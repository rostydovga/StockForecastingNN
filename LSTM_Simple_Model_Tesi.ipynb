{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWVVPkLD71vx"
      },
      "source": [
        "# Installazioni ed import necessari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7rGhzCoN0i9"
      },
      "outputs": [],
      "source": [
        "!mkdir images/\n",
        "!mkdir save_mat/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeDfyPb342Ml",
        "outputId": "d8595a47-28bd-4254-87a3-6e76688bf776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Installing collected packages: requests, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed requests-2.28.1 yfinance-0.1.74\n"
          ]
        }
      ],
      "source": [
        "!pip install lxml yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l764w5tZh1H",
        "outputId": "c8b32ac3-e6fb-42da-c792-ea471c4e3271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas_ta) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_ta) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_ta) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas_ta) (1.15.0)\n",
            "Building wheels for collected packages: pandas-ta\n",
            "  Building wheel for pandas-ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218923 sha256=98dfd98706331c2fffcdd1f8b50eccead132539a5b4b5542b0bf3dce0a0a4931\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/81/f0/cca85757840e4616a2c6b9fe12569d97d324c27cac60724c58\n",
            "Successfully built pandas-ta\n",
            "Installing collected packages: pandas-ta\n",
            "Successfully installed pandas-ta-0.3.14b0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas_ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_73-YuWDYtnF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import pandas_ta as ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB1OnNjqBZ3G"
      },
      "outputs": [],
      "source": [
        "def get_categorical_tickers():\n",
        "    '''\n",
        "    This Function returns a dictionary of tickers for different industry types\n",
        "    :return:\n",
        "    ticker_dict: Dictionary of 9 different industry types with over 8 tickers each\n",
        "    tickerSymbols: Set of three tickers\n",
        "    '''\n",
        "    ticker_dict = {}\n",
        "    all_tickers = []\n",
        "    ticker_dict['energy'] = ['XOM', 'CVX', 'SHEL', 'PTR', 'TTE', 'BP', 'PBR', 'SNP', 'SLB', 'VLO']\n",
        "    ticker_dict['materials'] = ['BHP', 'LIN', 'RIO', 'DD', 'SHW', 'CTA-PB', 'APD']\n",
        "    ticker_dict['industrials'] = ['UPS', 'HON', 'LMT', 'BA', 'GE', 'MMM', 'RTX', 'CAT', 'WM', 'ABB', 'ETN', 'EMR',\n",
        "                                  'FDX', 'TRI']\n",
        "    ticker_dict['utilities'] = ['NEE', 'DUK', 'NGG', 'AEP', 'XEL','AWK' ,'ETR', 'PCG']\n",
        "    ticker_dict['healthcare'] = ['UNH', 'JNJ', 'PFE', 'NVO', 'TMO', 'MRK', 'AZN', 'NVS', 'DHR', 'AMGN', 'CVS', 'GSK',\n",
        "                                 'ZTS', 'GILD']\n",
        "    ticker_dict['financials'] = ['BRK-A', 'V', 'JPM', 'BAC', 'MA', 'WFC', 'C-PJ', 'MS', 'RY', 'AXP']\n",
        "    ticker_dict['discretionary'] = ['AMZN', 'TSLA', 'HD', 'BABA', 'TM', 'NKE', 'MCD', 'SBUX', 'F', 'MAR', 'GM', 'ORLY',\n",
        "                                     'HMC', 'CMG', 'HLT'] # tolgo 'LILI'\n",
        "    ticker_dict['staples'] = ['WMT', 'PG', 'KO', 'COST', 'PEP', 'BUD', 'UL', 'TGT', 'MDLZ', 'CL', 'DG', 'KHC', 'KDP',\n",
        "                              'HSY']\n",
        "    ticker_dict['IT'] = ['AAPL', 'MSFT', 'TSM', 'NVDA', 'AVGO', 'CSCO', 'ORCL', 'ACN', 'ADBE', 'INTC', 'CRM', 'TXN',\n",
        "                         'QCOM', 'AMD', 'IBM', 'SONY', 'AMAT', 'INFY', 'ADI', 'MU', 'LRCX']\n",
        "    ticker_dict['communication'] = ['GOOG', 'DIS', 'VZ', 'CMCSA', 'TMUS', 'T', 'NFLX', 'SNAP', 'VOD',\n",
        "                                    'TWTR', 'EA'] # rimuovo FB, BAIDU\n",
        "    ticker_dict['estate'] = ['PLD', 'AMT', 'CCI', 'EQIX', 'SPG', 'DLR', 'WELL', 'EQR', 'AVB', 'WY', 'INVH', 'MAA']\n",
        "    ticker_keys = []\n",
        "    for key in ticker_dict.keys():\n",
        "        ticker_keys.append(key)\n",
        "        all_tickers.append(ticker_dict[key])\n",
        "    ticker_dict['all'] = all_tickers\n",
        "    tickerSymbols = ['BRK-A', 'GOOG', 'MSFT']\n",
        "    return ticker_dict, tickerSymbols\n",
        "\n",
        "def get_company_names():\n",
        "    '''\n",
        "    Get a dictionary of search strings corresponding to different ticker labels\n",
        "    :return:\n",
        "    ticker_dict: Dictionary of search strings given a stock ticker\n",
        "    '''\n",
        "    ticker_dict = {}\n",
        "    all_tickers = []\n",
        "    ticker_dict['energy'] = {'XOM': 'Exxon Mobil', 'CVX': 'Chevron', 'SHEL': 'Shell', 'PTR': 'PetroChina',\n",
        "                             'TTE': 'TotalEnergies', 'BP': 'BP', 'PBR': 'Petroleo Brasileiro',\n",
        "                             'SNP': 'China Petroleum', 'SLB': 'Schlumberger', 'VLO': 'Valero'}\n",
        "    '''\n",
        "    ticker_dict['materials'] = ['BHP', 'LIN', 'RIO', 'DD', 'SHW', 'CTA-PB', 'APD']\n",
        "    ticker_dict['industrials'] = ['UPS', 'HON', 'LMT', 'BA', 'GE', 'MMM', 'RTX', 'CAT', 'WM', 'ABB', 'ETN', 'EMR',\n",
        "                                  'FDX', 'TRI']\n",
        "    ticker_dict['utilities'] = ['NEE', 'DUK', 'NGG', 'AEP', 'XEL','AWK' ,'ETR', 'PCG']\n",
        "    ticker_dict['healthcare'] = ['UNH', 'JNJ', 'PFE', 'NVO', 'TMO', 'MRK', 'AZN', 'NVS', 'DHR', 'AMGN', 'CVS', 'GSK',\n",
        "                                 'ZTS', 'GILD']\n",
        "    ticker_dict['financials'] = ['BRK-A', 'V', 'JPM', 'BAC', 'MA', 'WFC', 'C-PJ', 'MS', 'RY', 'AXP']\n",
        "    ticker_dict['discretionary'] = ['AMZN', 'TSLA', 'HD', 'BABA', 'TM', 'NKE', 'MCD', 'SBUX', 'F', 'MAR', 'GM', 'ORLY',\n",
        "                                    'LILI', 'HMC', 'CMG', 'HLT']\n",
        "    ticker_dict['staples'] = ['WMT', 'PG', 'KO', 'COST', 'PEP', 'BUD', 'UL', 'TGT', 'MDLZ', 'CL', 'DG', 'KHC', 'KDP',\n",
        "                              'HSY']\n",
        "    ticker_dict['IT'] = ['AAPL', 'MSFT', 'TSM', 'NVDA', 'AVGO', 'CSCO', 'ORCL', 'ACN', 'ADBE', 'INTC', 'CRM', 'TXN',\n",
        "                         'QCOM', 'AMD', 'IBM', 'SONY', 'AMAT', 'INFY', 'ADI', 'MU', 'LRCX']\n",
        "    ticker_dict['communication'] = ['GOOG', 'FB', 'DIS', 'VZ', 'CMCSA', 'TMUS', 'T', 'NFLX', 'SNAP', 'VOD', 'BAIDU',\n",
        "                                    'TWTR', 'EA']\n",
        "    ticker_dict['estate'] = ['PLD', 'AMT', 'CCI', 'EQIX', 'SPG', 'DLR', 'WELL', 'EQR', 'AVB', 'WY', 'INVH', 'MAA']\n",
        "    ticker_keys = []\n",
        "    for key in ticker_dict.keys():\n",
        "        ticker_keys.append(key)\n",
        "        all_tickers.append(ticker_dict[key])\n",
        "    ticker_dict['all'] = all_tickers\n",
        "    '''\n",
        "    return ticker_dict\n",
        "\n",
        "def cross_corr(a,b):\n",
        "    '''\n",
        "    Compute the cross-correlation between\n",
        "    :param a: Time-series data of first stock\n",
        "    :param b: Time-series data of second stock\n",
        "    :return: Cross-correlation of the two stocks that are input\n",
        "    '''\n",
        "    return (a*b).sum()/((a**2).sum()*(b**2).sum())**0.5\n",
        "\n",
        "def get_tick_values(tickerSymbol, start, end):\n",
        "    '''\n",
        "    Function to extract the time series data\n",
        "    :param tickerSymbol: String of stock ticker\n",
        "    :param start: String of starting date of the time-series data\n",
        "    :param end: String of ending date of the time-series data\n",
        "    :return: type(list): Time series data\n",
        "    '''\n",
        "    tickerData = yf.Ticker(tickerSymbol)\n",
        "    tickerDf = yf.download(tickerSymbol, start=start, end=end)\n",
        "    tickerDf = tickerDf['Adj Close']\n",
        "    data = tickerDf\n",
        "    return data.values\n",
        "\n",
        "def get_control_vector(val):\n",
        "    '''\n",
        "    Returns the mask of day instances where stock purchase/sell decisions are to be made\n",
        "    :param val: Input array of stock values\n",
        "    :return: np.array of decisions maks labels (-2/0/2)\n",
        "    '''\n",
        "    return np.diff(np.sign(np.diff(val)))\n",
        "\n",
        "def buy_and_sell_bot(val,controls):\n",
        "    '''\n",
        "    Returns the growth of investment over time as function of the input decision mask and the stock values\n",
        "    :param val: np.array of the actual stock value over time\n",
        "    :param controls: np.array of the control mask to make purchase/sell decisions\n",
        "    :return: np.array of percentage growth value of the invested stock\n",
        "    '''\n",
        "    inv = []\n",
        "    curr_val = 100\n",
        "    inds = np.where(controls)[0]\n",
        "    buy_inds = np.where(controls>0)[0]\n",
        "    sell_inds = np.where(controls<0)[0]\n",
        "    max_limit = sell_inds[-1] if sell_inds[-1]>buy_inds[-1] else buy_inds[-1]\n",
        "    for i in range(buy_inds[0]+2):\n",
        "        inv.append(curr_val)\n",
        "    for i in range(buy_inds[0],max_limit+1):\n",
        "        if controls[i]>0:\n",
        "            buy_val = val[i+1]\n",
        "        elif controls[i]<0:\n",
        "            sell_val = val[i+1]\n",
        "            curr_val = curr_val*sell_val/buy_val\n",
        "        inv.append(curr_val)\n",
        "    if max_limit+1!=len(controls):\n",
        "        for i in range(len(controls)-max_limit-1):\n",
        "            inv.append(curr_val)\n",
        "    return inv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCNTjPHt7wPy"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.callbacks import History\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02q2F_ZWyK-X"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAy3SMy3yM_5"
      },
      "outputs": [],
      "source": [
        "class LSTM_Model():\n",
        "    '''\n",
        "    Class to train and infer stock price for one particular stock\n",
        "    '''\n",
        "    def __init__(self,tickerSymbol, start, end,\n",
        "                 past_history = 60, forward_look = 1, train_test_split = 0.8, batch_size = 30,\n",
        "                 epochs = 50, steps_per_epoch = 200, validation_steps = 50, verbose = 0, infer_train = True,\n",
        "                 depth = 1, naive = False, values = 200, plot_values = True, plot_bot = True,\n",
        "                 custom_loss = False):\n",
        "        '''\n",
        "        Initialize parameters for the class\n",
        "        :param tickerSymbol: String of Ticker symbol to train on\n",
        "        :param start: String of start date of time-series data\n",
        "        :param end: String of end date of time-series data\n",
        "        :param past_history: Int of past number of days to look at\n",
        "        :param forward_look: Int of future days to predict at a time\n",
        "        :param train_test_split: Float of fraction train-test split\n",
        "        :param batch_size: Int of mini-batch size\n",
        "        :param epochs: Int of total number of epochs in training\n",
        "        :param steps_per_epoch: Int for total number of mini-batches to run over per epoch\n",
        "        :param validation_steps: Int of total number of steps to use while validating with the dev set\n",
        "        :param verbose: Int to decide to print training stage results\n",
        "        :param infer_train: Flag to carry out prediction on training set\n",
        "        :param depth: Int to decide depth of stacked LSTM\n",
        "        :param naive: Flag for deciding if we need a Vanila model\n",
        "        :param values: Int for number of days to predict for by iteratively updating the time-series histroy\n",
        "        :param plot_values: Flag to plot\n",
        "        :param plot_bot: Flag to plot the investment growth by the decision making bot\n",
        "        :param custom_loss: Flag to decude if custom loss function needs to be applied\n",
        "        '''\n",
        "        self.tickerSymbol = tickerSymbol\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.past_history = past_history\n",
        "        self.forward_look = forward_look\n",
        "        self.train_test_split = train_test_split\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.validation_steps = validation_steps\n",
        "        self.verbose = verbose\n",
        "        self.values = values\n",
        "        self.depth = depth\n",
        "        self.naive = naive\n",
        "        self.plot_values = plot_values\n",
        "        self.plot_bot = plot_bot\n",
        "        self.infer_train = infer_train\n",
        "        self.custom_loss = custom_loss\n",
        "        tf.random.set_seed(1728)\n",
        "\n",
        "    def custom_loss_def(self,y_true,y_pred):\n",
        "        '''\n",
        "        Definition of the custom loss function\n",
        "        :param y_true: Np.array of true value\n",
        "        :param y_pred: np.array of predicted value\n",
        "        :return: Customised loss function as tf.tensor\n",
        "        '''\n",
        "        self.weights = np.float32(1.0 + 1.0*np.linspace(0,self.forward_look-1,self.forward_look)/200.0)\n",
        "        return tf.math.reduce_mean(tf.math.square(tf.multiply(self.weights,y_true - y_pred)))\n",
        "\n",
        "    def data_preprocess(self, dataset, iStart, iEnd, sHistory, forward_look=1):\n",
        "        '''\n",
        "        Preprocess the data to make either the test set or the train set\n",
        "        :param dataset: np.array of time-series data\n",
        "        :param iStart: int of index start\n",
        "        :param iEnd: int of index end\n",
        "        :param sHistory: int number of days in history that we need to look at\n",
        "        :param forward_look: int of number of days in the future that needs to predicted\n",
        "        :return: returns a list of test/train data\n",
        "        '''\n",
        "        self.data = []\n",
        "        self.target = []\n",
        "        iStart += sHistory\n",
        "        if iEnd is None:\n",
        "            iEnd = len(dataset) - forward_look + 1\n",
        "        for i in range(iStart, iEnd):\n",
        "            indices = range(i - sHistory, i)  # set the order\n",
        "            if forward_look > 1:\n",
        "                fwd_ind = range(i, i + forward_look)\n",
        "                fwd_entity = np.asarray([])\n",
        "                fwd_entity = np.append(fwd_entity, dataset[fwd_ind])\n",
        "            reshape_entity = np.asarray([])\n",
        "            reshape_entity = np.append(reshape_entity, dataset[\n",
        "                indices])  # Comment this out if there are multiple identifiers in the feature vector\n",
        "            self.data.append(np.reshape(reshape_entity, (sHistory, 1)))  #\n",
        "            if forward_look > 1:\n",
        "                self.target.append(np.reshape(fwd_entity, (forward_look, 1)))\n",
        "            else:\n",
        "                self.target.append(dataset[i])\n",
        "        self.data = np.array(self.data)\n",
        "        self.target = np.array(self.target)\n",
        "\n",
        "    def plot_history_values(self):\n",
        "        '''\n",
        "        Plots time-series data of the chosen ticker\n",
        "        '''\n",
        "        tickerData = yf.Ticker(self.tickerSymbol)\n",
        "        tickerDf = yf.download(self.tickerSymbol, start=self.start, end=self.end)\n",
        "        tickerDf = tickerDf['Adj Close']\n",
        "        data = tickerDf\n",
        "        y = data\n",
        "        y.index = data.index\n",
        "        y.plot()\n",
        "        plt.title(f\"{self.tickerSymbol}\")\n",
        "        plt.ylabel(\"price\")\n",
        "        plt.show()\n",
        "\n",
        "    def get_ticker_values(self):\n",
        "        '''\n",
        "        Get ticker values in a list\n",
        "        '''\n",
        "        tickerData = yf.Ticker(self.tickerSymbol)\n",
        "        tickerDf = yf.download(self.tickerSymbol, start=self.start, end=self.end)\n",
        "        tickerDf = tickerDf['Adj Close']\n",
        "        data = tickerDf\n",
        "        self.y = data.values\n",
        "\n",
        "    def prepare_test_train(self):\n",
        "        '''\n",
        "        Create the dataset from the extracted time-series data\n",
        "        '''\n",
        "        training_size = int(self.y.size * self.train_test_split)\n",
        "        training_mean = self.y[:training_size].mean()  # get the average\n",
        "        training_std = self.y[:training_size].std()  # std = a measure of how far away individual measurements tend to be from the mean value of a data set.\n",
        "        self.y = (self.y - training_mean) / training_std  # prep data, use mean and standard deviation to maintain distribution and ratios\n",
        "        self.data_preprocess(self.y, 0, training_size, self.past_history, forward_look = self.forward_look)\n",
        "        self.xtrain, self.ytrain = self.data, self.target\n",
        "        self.data_preprocess(self.y, training_size, None, self.past_history, forward_look = self.forward_look)\n",
        "        self.xtest, self.ytest = self.data, self.target\n",
        "\n",
        "    def create_p_test_train(self):\n",
        "        '''\n",
        "        Prepare shuffled train and test data\n",
        "        '''\n",
        "        BATCH_SIZE = self.batch_size\n",
        "        BUFFER_SIZE = self.y.size\n",
        "        p_train = tf.data.Dataset.from_tensor_slices((self.xtrain, self.ytrain))\n",
        "        self.p_train = p_train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "        p_test = tf.data.Dataset.from_tensor_slices((self.xtest, self.ytest))\n",
        "        self.p_test = p_test.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    def model_LSTM(self):\n",
        "        '''\n",
        "        Create the stacked LSTM model and train it using the shuffled train set\n",
        "        '''\n",
        "        self.model = tf.keras.models.Sequential()\n",
        "        if self.naive:\n",
        "            self.model.add(tf.keras.layers.LSTM(20, input_shape = self.xtrain.shape[-2:]))\n",
        "        else:\n",
        "            self.model.add(tf.keras.layers.LSTM(20, return_sequences=True, input_shape = self.xtrain.shape[-2:]))\n",
        "        for i in range(self.depth):\n",
        "            self.model.add(tf.keras.layers.LSTM(20, return_sequences=True))\n",
        "        if self.naive is False:\n",
        "            self.model.add(tf.keras.layers.LSTM(20))\n",
        "        self.model.add(tf.keras.layers.Dense(self.forward_look))\n",
        "        if self.custom_loss:\n",
        "            self.model.compile(optimizer='Adam',\n",
        "                      loss=self.custom_loss_def, metrics=['mse','mae'])\n",
        "        else:\n",
        "            self.model.compile(optimizer='Adam',\n",
        "                               loss='mse', metrics=['mse','mae'])\n",
        "\n",
        "        self.create_p_test_train()\n",
        "        self.hist = self.model.fit(self.p_train, epochs = self.epochs, steps_per_epoch = self.steps_per_epoch,\n",
        "                  validation_data = self.p_test, validation_steps = self.validation_steps,\n",
        "                  verbose = self.verbose)\n",
        "\n",
        "    def infer_values(self, xtest, ytest, ts):\n",
        "        '''\n",
        "        Infer values by using the test set\n",
        "        :param xtest: test dataset\n",
        "        :param ytest: actual value dataset\n",
        "        :param ts: tikcer symbol\n",
        "        :return: model variables that store predicted data\n",
        "        '''\n",
        "        self.pred = []\n",
        "        self.pred_update = []\n",
        "        self.usetest = xtest.copy()\n",
        "        if self.infer_train:\n",
        "            self.pred_train = []\n",
        "            self.pred_update_train = []\n",
        "            self.usetest_train = self.xtrain.copy()\n",
        "        for i in range(self.values):\n",
        "            self.y_pred = self.model.predict(xtest[i,:,:].reshape(1,xtest.shape[1],xtest.shape[2]))[0][:]\n",
        "            self.y_pred_update = self.model.predict(self.usetest[i,:,:].reshape(1,xtest.shape[1],xtest.shape[2]))[0][:]\n",
        "            self.pred.append(self.y_pred)\n",
        "            self.pred_update.append(self.y_pred_update)\n",
        "            self.usetest[np.linspace(i+1,i+self.past_history-1,self.past_history-1,dtype=int),np.linspace(self.past_history-2,0,self.past_history-1,dtype=int),:] =  self.y_pred_update[0]\n",
        "            if self.infer_train:\n",
        "                self.y_pred_train = self.model.predict(self.xtrain[i, :, :].reshape(1, self.xtrain.shape[1], self.xtrain.shape[2]))[0][:]\n",
        "                self.y_pred_update_train = \\\n",
        "                self.model.predict(self.usetest_train[i, :, :].reshape(1, self.xtrain.shape[1], self.xtrain.shape[2]))[0][:]\n",
        "                self.pred_train.append(self.y_pred_train)\n",
        "                self.pred_update_train.append(self.y_pred_update_train)\n",
        "                self.usetest_train[np.linspace(i + 1, i + self.past_history - 1, self.past_history - 1, dtype=int),\n",
        "                np.linspace(self.past_history - 2, 0, self.past_history - 1, dtype=int), :] = self.y_pred_update_train[0]\n",
        "        self.pred = np.array(self.pred)\n",
        "        self.pred_update = np.array(self.pred_update)\n",
        "        self.RMS_error = self.hist.history['val_mse'][-1]\n",
        "        self.RMS_error_train = self.hist.history['mse'][-1]\n",
        "        self.MAE_error = self.hist.history['val_mae'][-1]\n",
        "        self.MAE_error_train = self.hist.history['mae'][-1]\n",
        "        if self.infer_train:\n",
        "            self.pred = np.array(self.pred)\n",
        "            self.pred_update_train = np.array(self.pred_update_train)\n",
        "        if self.forward_look>1:\n",
        "            self.RMS_error_update = (np.mean(((self.ytest[:self.values - 1, 0, 0] - self.pred_update[1:, 0]) / (\n",
        "            self.ytest[:self.values - 1, 0, 0])) ** 2)) ** 0.5/self.batch_size\n",
        "            if self.infer_train:\n",
        "                self.RMS_error_update_train = (np.mean(((self.ytrain[:self.values - 1, 0, 0] - self.pred_update_train[1:, 0]) / (\n",
        "                    self.ytrain[:self.values - 1, 0, 0])) ** 2)) ** 0.5/self.batch_size\n",
        "        else:\n",
        "            self.RMS_error_update = (np.mean(\n",
        "                ((self.ytest[:self.values - 1] - self.pred_update[1:]) / (self.ytest[:self.values - 1])) ** 2)) ** 0.5/self.batch_size\n",
        "            if self.infer_train:\n",
        "                self.RMS_error_update_train = (np.mean(((self.ytrain[:self.values - 1] - self.pred_update_train[1:]) / (\n",
        "                    self.ytrain[:self.values - 1])) ** 2)) ** 0.5/self.batch_size\n",
        "\n",
        "    def plot_test_values(self):\n",
        "        '''\n",
        "        Plot predicted values against actual values\n",
        "        '''\n",
        "        plt.figure()\n",
        "        if self.forward_look>1:\n",
        "            plt.plot(self.yt[:self.values-1,0,0],label='actual (%s)'%self.ts)\n",
        "            plt.plot(self.pred[1:,0],label='predicted (%s)'%self.ts)\n",
        "            plt.plot(self.pred_update[1:,0],label='predicted (update)')\n",
        "            plt.xlabel(\"Days\")\n",
        "            plt.ylabel(\"Normalized stock price\")\n",
        "            plt.title('The relative RMS error is %f' % self.RMS_error)\n",
        "            plt.legend()\n",
        "            plt.savefig('images/Stock_prediction_%d_%d_%d_%d_%s_%s.png' % (\n",
        "            self.depth, int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)))\n",
        "            plt.clf()\n",
        "            plt.figure()\n",
        "            plt.plot(self.pred[1:, 0]-self.pred_update[1:,0], label='difference (%s)' % self.ts)\n",
        "            plt.xlabel(\"Days\")\n",
        "            plt.ylabel(\"Prediction difference\")\n",
        "            plt.savefig('images/Difference_%d_%d_%d_%d_%s_%s.png' % (\n",
        "            self.depth, int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)))\n",
        "            plt.clf()\n",
        "            np.savez('save_mat/store_%d_%d_%d_%d_%s_%s.png'%(\n",
        "            self.depth,int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)),\n",
        "            y = self.yt[:self.values-1,0,0],pred = self.pred[1:,0],pred_up = self.pred_update[1:,0])\n",
        "        else:\n",
        "            plt.plot(self.yt[:self.values-1],label='actual (%s)'%self.ts)\n",
        "            plt.plot(self.pred[1:],label='predicted (%s)'%self.ts)\n",
        "            #plt.plot(self.pred_update[1:],label='predicted (update)')\n",
        "            plt.xlabel(\"Days\")\n",
        "            plt.ylabel(\"Normalized stock price\")\n",
        "            plt.title('The relative RMS error is %f' % self.RMS_error)\n",
        "            plt.legend()\n",
        "            plt.savefig('images/Stock_prediction_%d_%d_%d_%d_%s_%s.png'%(\n",
        "            self.depth,int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)))\n",
        "            plt.clf()\n",
        "            plt.figure()\n",
        "            plt.plot(self.pred[1:] - self.pred_update[1:], label='difference (%s)' % self.ts)\n",
        "            plt.xlabel(\"Days\")\n",
        "            plt.ylabel(\"Prediction difference\")\n",
        "            plt.savefig('images/Difference_%d_%d_%d_%d_%s_%s.png' % (\n",
        "            self.depth, int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)))\n",
        "            plt.clf()\n",
        "            np.savez('save_mat/store_%d_%d_%d_%d_%s_%s.png' % (\n",
        "            self.depth, int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)),\n",
        "            y=self.yt[:self.values - 1], pred=self.pred[1:], pred_up=self.pred_update[1:])\n",
        "        print('The relative test RMS error is %f'%self.RMS_error)\n",
        "        print('The relative test MAE is %f' % self.MAE_error)\n",
        "        print('The relative test RMS error for the updated dataset is %f' % self.RMS_error_update)\n",
        "        if self.infer_train:\n",
        "            print('The relative train RMS error is %f' % self.RMS_error_train)\n",
        "            print('The relative train MAE is %f' % self.MAE_error_train)\n",
        "            print('The relative train RMS error for the updated dataset is %f' % self.RMS_error_update_train)\n",
        "            \n",
        "    def arch_plot(self):\n",
        "        '''\n",
        "        Plot the network architecture\n",
        "        '''\n",
        "        dot_img_file = 'images/LSTM_arch_depth%d_naive%d.png' %( self.depth, int(self.naive))\n",
        "        tf.keras.utils.plot_model(self.model, to_file=dot_img_file, show_shapes=True)\n",
        "    \n",
        "\n",
        "    def full_workflow(self, model = None):\n",
        "        '''\n",
        "        Workflow to carry out the entire process end-to-end\n",
        "        :param model: Choose which model to use to predict inferred values\n",
        "        :return:\n",
        "        '''\n",
        "        self.get_ticker_values()\n",
        "        self.prepare_test_train()\n",
        "        self.model_LSTM()\n",
        "        if model is None:\n",
        "            self.xt = self.xtest\n",
        "            self.yt = self.ytest\n",
        "            self.ts = self.tickerSymbol\n",
        "        else:\n",
        "            self.xt = model.xtest\n",
        "            self.yt = model.ytest\n",
        "            self.ts = model.tickerSymbol\n",
        "        self.infer_values(self.xt, self.yt, self.ts)\n",
        "        # self.arch_plot()\n",
        "\n",
        "    def full_workflow_and_plot(self, model = None):\n",
        "        '''\n",
        "        Workflow to carry out the entire process end-to-end\n",
        "        :param model: Choose which model to use to plot inferred values\n",
        "        :return:\n",
        "        '''\n",
        "        self.full_workflow(model = model)\n",
        "        self.plot_test_values()\n",
        "        \n",
        "\n",
        "    def plot_bot_decision(self):\n",
        "        '''\n",
        "        calculate investment growth from the inferred prediction value and plot the resulting growth\n",
        "        '''\n",
        "        if self.forward_look > 1:\n",
        "            ideal = self.yt[:self.values - 1, 0, 0]\n",
        "            pred = np.asarray(self.pred[1:, 0]).reshape(-1,)\n",
        "            pred_update = np.asarray(self.pred_update[1:, 0]).reshape(-1,)\n",
        "        else:\n",
        "            ideal = self.yt[:self.values - 1]\n",
        "            pred = np.asarray(self.pred[1:]).reshape(-1,)\n",
        "            pred_update = np.asarray(self.pred_update[1:]).reshape(-1,)\n",
        "        control_ideal = get_control_vector(ideal)\n",
        "        control_pred = get_control_vector(pred)\n",
        "        control_pred_update = get_control_vector(pred_update)\n",
        "        bot_ideal = buy_and_sell_bot(ideal, control_ideal)\n",
        "        bot_pred = buy_and_sell_bot(ideal, control_pred)\n",
        "        bot_pred_update = buy_and_sell_bot(ideal, control_pred_update)\n",
        "        plt.figure()\n",
        "        plt.plot(bot_ideal, label='Ideal case (%.2f)'%bot_ideal[-1])\n",
        "        plt.plot(bot_pred, label='From prediction (%.2f)'%bot_pred[-1])\n",
        "        plt.plot(bot_pred_update, label='From prediction (updated) (%.2f)'%bot_pred_update[-1])\n",
        "        plt.plot(ideal / ideal[0] * 100.0, label='Stock value(%s)' % self.ts)\n",
        "        plt.xlabel(\"Days\")\n",
        "        plt.ylabel(\"Percentage growth\")\n",
        "        plt.legend()\n",
        "        plt.savefig('images/Bot_prediction_%d_%d_%d_%d_%s_%s.png' % (self.depth, int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)))\n",
        "        np.savez('save_mat/bot_%d_%d_%d_%d_%s_%s.png' % (\n",
        "        self.depth, int(self.naive), self.past_history, self.forward_look, self.ts, int(self.custom_loss)),\n",
        "        ideal = bot_ideal, pred  = bot_pred, pred_up = bot_pred_update)\n",
        "        plt.clf()\n",
        "\n",
        "\n",
        "    def get_predicted_values(self):\n",
        "      return self.xt, self.yt, self.pred, self.pred_update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT-W6lOON32_"
      },
      "source": [
        "# Funzione Investimento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIxDTKsRN7yg"
      },
      "outputs": [],
      "source": [
        "def calculate_investment(dataset ,initial_investment=1_000):\n",
        "  '''\n",
        "  Return the final value of investment\n",
        "  '''\n",
        "  open_close_prices = dataset[['Open', 'Close']]\n",
        "  decisions = dataset['operation'] # if 1 -> buy, else sell\n",
        "  total_cash = initial_investment\n",
        "  price_decision = 1\n",
        "\n",
        "  #creo il dizionario di analisi\n",
        "  stats = {}\n",
        "  stats['cash invested'] = []\n",
        "  stats['Buy at'] = []\n",
        "  stats['Close at'] = []\n",
        "  stats['n stock buyed'] = []\n",
        "  stats['Bot decision'] = []\n",
        "  stats['cash returned'] = []\n",
        "\n",
        "\n",
        "\n",
        "  # per le operazioni buy\n",
        "  for i in open_close_prices.index:\n",
        "    \n",
        "    open_price = open_close_prices['Open'].loc[i]\n",
        "    close_price = open_close_prices['Close'].loc[i]\n",
        "    if(decisions.loc[i] == 1):\n",
        "      #print(f'\\nBuy {n_stock} stock for {open_price}')\n",
        "      # a fine giornata chiudo la posizione aperta in precedenza\n",
        "      price_decision = close_price\n",
        "      price_open_operation = open_price\n",
        "      #print(f'Close with return at {cash}')\n",
        "    else:\n",
        "      # se decision sell\n",
        "      price_decision = open_price\n",
        "      price_open_operation = close_price\n",
        "\n",
        "    n_stock = total_cash / price_open_operation\n",
        "    cash = n_stock * price_decision\n",
        "\n",
        "    stats['cash invested'].append(total_cash)\n",
        "    stats['Buy at'].append(open_price)\n",
        "    stats['Close at'].append(close_price)\n",
        "    stats['n stock buyed'].append(n_stock)\n",
        "    stats['Bot decision'].append(decisions.loc[i])\n",
        "    stats['cash returned'].append(cash)\n",
        "    \n",
        "    total_cash = cash\n",
        "\n",
        "\n",
        "  return total_cash, stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IlGjvx6qmzO"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VugpTw-Bq-av"
      },
      "outputs": [],
      "source": [
        "start = '2010-01-01'\n",
        "end = '2022-08-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhA7eDw4RfF1"
      },
      "outputs": [],
      "source": [
        "stock = 'AAPL'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test su unico titolo"
      ],
      "metadata": {
        "id": "4dv7fEsybJvs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIZnMeb3eRpc",
        "outputId": "7d35dfd7-baf8-467b-9411-b7962c82d7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "df = yf.download('AAPL', start, end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItV7dw7peXnW",
        "outputId": "30ce6e94-f344-4211-e6b0-3e0ccc1d0d8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Open         1.340800e+02\n",
              "High         1.347400e+02\n",
              "Low          1.317200e+02\n",
              "Close        1.326900e+02\n",
              "Adj Close    1.313335e+02\n",
              "Volume       9.911660e+07\n",
              "Name: 2020-12-31 00:00:00, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "split = 0.8747\n",
        "index = int(len(df)*split)\n",
        "df.iloc[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk1e6WfWRWlG"
      },
      "outputs": [],
      "source": [
        "diz = {}\n",
        "diz['stock'] = []\n",
        "diz['roi'] = []\n",
        "diz['gain'] = []\n",
        "\n",
        "\n",
        "# scarico i dati\n",
        "df = yf.download(stock, start, end)\n",
        "\n",
        "index = int(len(df)*split)\n",
        "values = df.iloc[index:].shape[0]\n",
        "# creo il modello\n",
        "LSTM_1 = LSTM_Model(tickerSymbol = stock , start = start, end = end, depth = 0, epochs=50, values=252, naive = True, verbose = True, train_test_split=0.8747) \n",
        "LSTM_1.full_workflow()\n",
        "\n",
        "xt, yt, pred, pred_update = LSTM_1.get_predicted_values()\n",
        "df_test = df[index:index+pred.shape[0]].copy()\n",
        "\n",
        "pred_r = pd.Series(pred.reshape(-1), index=df_test.index)\n",
        "df_test['pred'] = pred_r\n",
        "\n",
        "mean_open = df[:index].Open.mean()\n",
        "std_open = df[:index].Open.std()\n",
        "\n",
        "open_norm = (df_test.Open - mean_open) / std_open\n",
        "df_test['open_norm'] = open_norm\n",
        "df_test['operation'] = np.where(df_test['pred'] > df_test['open_norm'], 1, 0 )\n",
        "tot, stats = calculate_investment(df_test,df_test.Open.iloc[0])\n",
        "\n",
        "roi = (tot - df_test.Open.iloc[0])/ df_test.Open.iloc[0]\n",
        "\n",
        "diz['stock'].append(stock)\n",
        "diz['roi'].append(roi)\n",
        "diz['gain'].append(tot)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOPJyExWX12d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5097bd0c-3ce5-4fbd-fe0e-8c4340c2e9ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(252, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVkMHUPPc9Ir",
        "outputId": "c392a43c-cb40-4929-f515-63e5bf44a458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(252, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "SVmkSLpZX6z3",
        "outputId": "87f2793e-7af9-4797-baa5-783acb50e7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd3606cc550>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "plt.plot(df_test.index,pd.DataFrame(stats)['cash returned'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "bbCDq_KdTDlX",
        "outputId": "9543a349-ce14-479a-938f-dfb598c406a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  stock       roi       gain\n",
              "0  AAPL  0.348156  180.76071"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce2429d6-ba58-4ac3-98d5-789dd67081e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>roi</th>\n",
              "      <th>gain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.348156</td>\n",
              "      <td>180.76071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce2429d6-ba58-4ac3-98d5-789dd67081e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce2429d6-ba58-4ac3-98d5-789dd67081e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce2429d6-ba58-4ac3-98d5-789dd67081e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "pd.DataFrame(diz)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test su più titoli"
      ],
      "metadata": {
        "id": "IHM1zJbCbR0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5Nknp_vrqn_Y"
      },
      "outputs": [],
      "source": [
        "# prelevo i dati\n",
        "td, _ = get_categorical_tickers()\n",
        "td.pop('all')\n",
        "diz = {}\n",
        "diz['stock'] = []\n",
        "diz['roi'] = []\n",
        "diz['gain'] = []\n",
        "\n",
        "for k in td.keys():\n",
        "\n",
        "  for stock in td[k][:3]:\n",
        "    # scarico i dati\n",
        "    df = yf.download(stock, start, end)\n",
        "\n",
        "    split = 0.8967\n",
        "    index = int(len(df)*split)\n",
        "    values = df.iloc[index:].shape[0]\n",
        "    # creo il modello\n",
        "    LSTM_1 = LSTM_Model(tickerSymbol = stock , start = start, end = end, depth = 0, epochs=50, values=252, naive = True, verbose = True, train_test_split=0.8747)\n",
        "    LSTM_1.full_workflow()\n",
        "\n",
        "    xt, yt, pred, pred_update = LSTM_1.get_predicted_values()\n",
        "    df_test = df[index:index+pred.shape[0]].copy()\n",
        "\n",
        "    pred_r = pd.Series(pred.reshape(-1), index=df_test.index)\n",
        "    df_test['pred'] = pred_r\n",
        "\n",
        "    mean_open = df[:index].Open.mean()\n",
        "    std_open = df[:index].Open.std()\n",
        "\n",
        "    open_norm = (df_test.Open - mean_open) / std_open\n",
        "    df_test['open_norm'] = open_norm\n",
        "    df_test['operation'] = np.where(df_test['pred'] > df_test['open_norm'], 1, 0 )\n",
        "    tot, stats = calculate_investment(df_test,df_test.Open.iloc[0])\n",
        "\n",
        "    roi = (tot - df_test.Open.iloc[0])/ df_test.Open.iloc[0]\n",
        "\n",
        "    diz['stock'].append(stock)\n",
        "    diz['roi'].append(roi)\n",
        "    diz['gain'].append(tot)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DrAxgy2nrHE9",
        "outputId": "8e2a5274-b3ae-4da3-e9e6-a7f8098c09c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-87e59aff-05a7-43c8-a93f-f6364e233af5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>roi</th>\n",
              "      <th>gain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>AMT</td>\n",
              "      <td>0.027956</td>\n",
              "      <td>249.937226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>0.052546</td>\n",
              "      <td>271.009504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PG</td>\n",
              "      <td>0.054642</td>\n",
              "      <td>142.925093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>PLD</td>\n",
              "      <td>0.059348</td>\n",
              "      <td>117.185067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVX</td>\n",
              "      <td>0.068860</td>\n",
              "      <td>109.718462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.070713</td>\n",
              "      <td>182.237433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>WMT</td>\n",
              "      <td>0.071516</td>\n",
              "      <td>149.069231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PFE</td>\n",
              "      <td>0.103286</td>\n",
              "      <td>41.009120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LMT</td>\n",
              "      <td>0.118178</td>\n",
              "      <td>433.182220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DUK</td>\n",
              "      <td>0.146679</td>\n",
              "      <td>112.707099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NEE</td>\n",
              "      <td>0.159492</td>\n",
              "      <td>91.066501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>BRK-A</td>\n",
              "      <td>0.173268</td>\n",
              "      <td>472579.320509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>UPS</td>\n",
              "      <td>0.181034</td>\n",
              "      <td>211.192570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>JNJ</td>\n",
              "      <td>0.183773</td>\n",
              "      <td>186.834886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NGG</td>\n",
              "      <td>0.212837</td>\n",
              "      <td>74.346937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>GOOG</td>\n",
              "      <td>0.242602</td>\n",
              "      <td>141.355949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XOM</td>\n",
              "      <td>0.376176</td>\n",
              "      <td>77.630067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BHP</td>\n",
              "      <td>0.400629</td>\n",
              "      <td>88.898062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RIO</td>\n",
              "      <td>0.492286</td>\n",
              "      <td>119.382843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.687599</td>\n",
              "      <td>227.724555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87e59aff-05a7-43c8-a93f-f6364e233af5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87e59aff-05a7-43c8-a93f-f6364e233af5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87e59aff-05a7-43c8-a93f-f6364e233af5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    stock       roi           gain\n",
              "31    AMT  0.027956     249.937226\n",
              "25   MSFT  0.052546     271.009504\n",
              "22     PG  0.054642     142.925093\n",
              "30    PLD  0.059348     117.185067\n",
              "1     CVX  0.068860     109.718462\n",
              "18   AMZN  0.070713     182.237433\n",
              "21    WMT  0.071516     149.069231\n",
              "14    PFE  0.103286      41.009120\n",
              "8     LMT  0.118178     433.182220\n",
              "10    DUK  0.146679     112.707099\n",
              "9     NEE  0.159492      91.066501\n",
              "15  BRK-A  0.173268  472579.320509\n",
              "6     UPS  0.181034     211.192570\n",
              "13    JNJ  0.183773     186.834886\n",
              "11    NGG  0.212837      74.346937\n",
              "27   GOOG  0.242602     141.355949\n",
              "0     XOM  0.376176      77.630067\n",
              "3     BHP  0.400629      88.898062\n",
              "5     RIO  0.492286     119.382843\n",
              "24   AAPL  0.687599     227.724555"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(diz).sort_values(by='roi').tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "gMVCRzdcA0eO",
        "outputId": "8e26a608-28ad-4102-9469-9566e00639ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    LSTM_1.model,\n",
        "    #to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=False,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    layer_range=None,\n",
        "    show_layer_activations=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test su liste di titoli a scelta"
      ],
      "metadata": {
        "id": "8b-6WQ6rbgNR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7asalT5BqS1"
      },
      "outputs": [],
      "source": [
        "stock_list_exam = ['^GSPC', '^FTSE', '^GDAXI','AAPL'] # '^NSEI',"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANQ6AeODZcSd"
      },
      "outputs": [],
      "source": [
        "stock_list_exam = ['NEE', 'BRK-A', 'UPS', 'JNJ', 'NGG', 'GOOG', 'XOM', 'BHP', 'RIO', 'AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCyusav54YoD"
      },
      "outputs": [],
      "source": [
        "stock_list_exam = ['AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn-FRB6XZ3IR"
      },
      "outputs": [],
      "source": [
        "start = '2010-01-01'\n",
        "end = '2022-08-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "veQf55RaBrIz",
        "outputId": "f3b3cf5a-feaf-46b0-ced0-2f88eee4091d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 16ms/step - loss: 0.1227 - mse: 0.1227 - mae: 0.1883 - val_loss: 0.2834 - val_mse: 0.2834 - val_mae: 0.4446\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0335 - val_loss: 0.1403 - val_mse: 0.1403 - val_mae: 0.2971\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0286 - val_loss: 0.1024 - val_mse: 0.1024 - val_mae: 0.2560\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0275 - val_loss: 0.0872 - val_mse: 0.0872 - val_mae: 0.2410\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0267 - val_loss: 0.0668 - val_mse: 0.0668 - val_mae: 0.2114\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0261 - val_loss: 0.0488 - val_mse: 0.0488 - val_mae: 0.1777\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0249 - val_loss: 0.0413 - val_mse: 0.0413 - val_mae: 0.1638\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0248 - val_loss: 0.0284 - val_mse: 0.0284 - val_mae: 0.1328\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0241 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1186\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0235 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1272\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0223 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.1044\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0232 - val_loss: 0.0272 - val_mse: 0.0272 - val_mae: 0.1392\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0219 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0956\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0216 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0982\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0208 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0819\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0211 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0929\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0210 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1099\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 0.0266 - val_mse: 0.0266 - val_mae: 0.1419\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0195 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0772\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0195 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0792\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0196 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0765\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.1023\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0188 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0808\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0874\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0906\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0754\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0175 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0874\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0899\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 17ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0175 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0940\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0171 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0768\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0897\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0636\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 9.4859e-04 - mse: 9.4859e-04 - mae: 0.0166 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0619\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0177 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0780\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0175 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0887\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.8241e-04 - mse: 9.8241e-04 - mae: 0.0172 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0841\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0646\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.9208e-04 - mse: 9.9208e-04 - mae: 0.0166 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0903\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.5630e-04 - mse: 9.5630e-04 - mae: 0.0171 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0687\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0926\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0166 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0744\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.8995e-04 - mse: 9.8995e-04 - mae: 0.0166 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0674\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.2235e-04 - mse: 9.2235e-04 - mae: 0.0161 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0677\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.3372e-04 - mse: 9.3372e-04 - mae: 0.0165 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0882\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0176 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0681\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.9365e-04 - mse: 9.9365e-04 - mae: 0.0171 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0657\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 9.3803e-04 - mse: 9.3803e-04 - mae: 0.0165 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0760\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0171 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0628\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0616\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 9.4431e-04 - mse: 9.4431e-04 - mae: 0.0165 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0741\n",
            "The relative test RMS error is 0.009159\n",
            "The relative test MAE is 0.074051\n",
            "The relative test RMS error for the updated dataset is 0.004746\n",
            "The relative train RMS error is 0.000944\n",
            "The relative train MAE is 0.016475\n",
            "The relative train RMS error for the updated dataset is 0.001148\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 14ms/step - loss: 0.1085 - mse: 0.1085 - mae: 0.1878 - val_loss: 1.8395 - val_mse: 1.8395 - val_mae: 1.2597\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0519 - val_loss: 1.2012 - val_mse: 1.2012 - val_mae: 1.0134\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0452 - val_loss: 0.9056 - val_mse: 0.9056 - val_mae: 0.8694\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0420 - val_loss: 0.6893 - val_mse: 0.6893 - val_mae: 0.7485\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0391 - val_loss: 0.5443 - val_mse: 0.5443 - val_mae: 0.6541\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0375 - val_loss: 0.4734 - val_mse: 0.4734 - val_mae: 0.6059\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0351 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.5859\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0352 - val_loss: 0.3698 - val_mse: 0.3698 - val_mae: 0.5261\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0333 - val_loss: 0.3437 - val_mse: 0.3437 - val_mae: 0.5050\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0325 - val_loss: 0.3621 - val_mse: 0.3621 - val_mae: 0.5319\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0315 - val_loss: 0.3146 - val_mse: 0.3146 - val_mae: 0.4848\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0308 - val_loss: 0.3061 - val_mse: 0.3061 - val_mae: 0.4809\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0298 - val_loss: 0.2910 - val_mse: 0.2910 - val_mae: 0.4673\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0291 - val_loss: 0.2743 - val_mse: 0.2743 - val_mae: 0.4509\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0285 - val_loss: 0.2638 - val_mse: 0.2638 - val_mae: 0.4420\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0282 - val_loss: 0.2506 - val_mse: 0.2506 - val_mae: 0.4289\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0286 - val_loss: 0.2283 - val_mse: 0.2283 - val_mae: 0.4036\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0280 - val_loss: 0.2342 - val_mse: 0.2342 - val_mae: 0.4147\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0268 - val_loss: 0.2123 - val_mse: 0.2123 - val_mae: 0.3892\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0266 - val_loss: 0.2127 - val_mse: 0.2127 - val_mae: 0.3923\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0268 - val_loss: 0.2138 - val_mse: 0.2138 - val_mae: 0.3972\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0260 - val_loss: 0.2128 - val_mse: 0.2128 - val_mae: 0.3975\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0260 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3813\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0261 - val_loss: 0.1839 - val_mse: 0.1839 - val_mae: 0.3621\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0256 - val_loss: 0.1835 - val_mse: 0.1835 - val_mae: 0.3637\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0258 - val_loss: 0.1815 - val_mse: 0.1815 - val_mae: 0.3626\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0252 - val_loss: 0.1585 - val_mse: 0.1585 - val_mae: 0.3288\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0254 - val_loss: 0.1647 - val_mse: 0.1647 - val_mae: 0.3411\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0250 - val_loss: 0.1807 - val_mse: 0.1807 - val_mae: 0.3655\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0257 - val_loss: 0.1592 - val_mse: 0.1592 - val_mae: 0.3361\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0253 - val_loss: 0.1804 - val_mse: 0.1804 - val_mae: 0.3680\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0256 - val_loss: 0.1539 - val_mse: 0.1539 - val_mae: 0.3293\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0246 - val_loss: 0.1517 - val_mse: 0.1517 - val_mae: 0.3275\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0253 - val_loss: 0.1479 - val_mse: 0.1479 - val_mae: 0.3235\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0255 - val_loss: 0.1276 - val_mse: 0.1276 - val_mae: 0.2876\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0246 - val_loss: 0.1495 - val_mse: 0.1495 - val_mae: 0.3250\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0255 - val_loss: 0.1450 - val_mse: 0.1450 - val_mae: 0.3184\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0250 - val_loss: 0.1428 - val_mse: 0.1428 - val_mae: 0.3160\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0252 - val_loss: 0.1309 - val_mse: 0.1309 - val_mae: 0.2949\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0249 - val_loss: 0.1508 - val_mse: 0.1508 - val_mae: 0.3290\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0245 - val_loss: 0.1413 - val_mse: 0.1413 - val_mae: 0.3148\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0244 - val_loss: 0.1293 - val_mse: 0.1293 - val_mae: 0.2947\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0247 - val_loss: 0.1304 - val_mse: 0.1304 - val_mae: 0.2975\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0254 - val_loss: 0.1368 - val_mse: 0.1368 - val_mae: 0.3074\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0253 - val_loss: 0.1281 - val_mse: 0.1281 - val_mae: 0.2930\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0244 - val_loss: 0.1367 - val_mse: 0.1367 - val_mae: 0.3087\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0247 - val_loss: 0.1364 - val_mse: 0.1364 - val_mae: 0.3078\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0252 - val_loss: 0.1185 - val_mse: 0.1185 - val_mae: 0.2767\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0250 - val_loss: 0.1295 - val_mse: 0.1295 - val_mae: 0.2962\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0250 - val_loss: 0.1405 - val_mse: 0.1405 - val_mae: 0.3158\n",
            "The relative test RMS error is 0.140547\n",
            "The relative test MAE is 0.315839\n",
            "The relative test RMS error for the updated dataset is 0.005149\n",
            "The relative train RMS error is 0.001469\n",
            "The relative train MAE is 0.024972\n",
            "The relative train RMS error for the updated dataset is 0.002451\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 14ms/step - loss: 0.1531 - mse: 0.1531 - mae: 0.2030 - val_loss: 2.0410 - val_mse: 2.0410 - val_mae: 1.3203\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0609 - val_loss: 1.8118 - val_mse: 1.8118 - val_mae: 1.2366\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0549 - val_loss: 1.5428 - val_mse: 1.5428 - val_mae: 1.1341\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0503 - val_loss: 1.3038 - val_mse: 1.3038 - val_mae: 1.0312\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0480 - val_loss: 1.0755 - val_mse: 1.0755 - val_mae: 0.9248\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0453 - val_loss: 0.9298 - val_mse: 0.9298 - val_mae: 0.8526\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0436 - val_loss: 0.8376 - val_mse: 0.8376 - val_mae: 0.8077\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0417 - val_loss: 0.7065 - val_mse: 0.7065 - val_mae: 0.7335\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0405 - val_loss: 0.5988 - val_mse: 0.5988 - val_mae: 0.6620\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0393 - val_loss: 0.5775 - val_mse: 0.5775 - val_mae: 0.6573\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0375 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.5897\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0368 - val_loss: 0.4497 - val_mse: 0.4497 - val_mae: 0.5719\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0366 - val_loss: 0.3842 - val_mse: 0.3842 - val_mae: 0.5181\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0357 - val_loss: 0.3329 - val_mse: 0.3329 - val_mae: 0.4751\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0346 - val_loss: 0.3594 - val_mse: 0.3594 - val_mae: 0.5089\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0355 - val_loss: 0.3395 - val_mse: 0.3395 - val_mae: 0.4964\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0334 - val_loss: 0.3751 - val_mse: 0.3751 - val_mae: 0.5369\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0343 - val_loss: 0.2568 - val_mse: 0.2568 - val_mae: 0.4178\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0328 - val_loss: 0.2728 - val_mse: 0.2728 - val_mae: 0.4390\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0331 - val_loss: 0.2209 - val_mse: 0.2209 - val_mae: 0.3846\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0331 - val_loss: 0.2484 - val_mse: 0.2484 - val_mae: 0.4183\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0325 - val_loss: 0.2396 - val_mse: 0.2396 - val_mae: 0.4101\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0323 - val_loss: 0.2532 - val_mse: 0.2532 - val_mae: 0.4277\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0324 - val_loss: 0.2365 - val_mse: 0.2365 - val_mae: 0.4102\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0323 - val_loss: 0.2358 - val_mse: 0.2358 - val_mae: 0.4123\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0321 - val_loss: 0.2162 - val_mse: 0.2162 - val_mae: 0.3894\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0319 - val_loss: 0.2191 - val_mse: 0.2191 - val_mae: 0.3926\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0320 - val_loss: 0.2525 - val_mse: 0.2525 - val_mae: 0.4320\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0315 - val_loss: 0.2408 - val_mse: 0.2408 - val_mae: 0.4183\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0324 - val_loss: 0.2322 - val_mse: 0.2322 - val_mae: 0.4099\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0317 - val_loss: 0.2580 - val_mse: 0.2580 - val_mae: 0.4399\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0323 - val_loss: 0.2180 - val_mse: 0.2180 - val_mae: 0.3924\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0317 - val_loss: 0.1961 - val_mse: 0.1961 - val_mae: 0.3660\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0324 - val_loss: 0.2387 - val_mse: 0.2387 - val_mae: 0.4139\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0320 - val_loss: 0.2709 - val_mse: 0.2709 - val_mae: 0.4510\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0323 - val_loss: 0.2430 - val_mse: 0.2430 - val_mae: 0.4207\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0320 - val_loss: 0.2599 - val_mse: 0.2599 - val_mae: 0.4384\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0323 - val_loss: 0.2242 - val_mse: 0.2242 - val_mae: 0.3971\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0309 - val_loss: 0.2472 - val_mse: 0.2472 - val_mae: 0.4208\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0318 - val_loss: 0.2975 - val_mse: 0.2975 - val_mae: 0.4767\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0319 - val_loss: 0.2767 - val_mse: 0.2767 - val_mae: 0.4545\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0310 - val_loss: 0.2440 - val_mse: 0.2440 - val_mae: 0.4177\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0308 - val_loss: 0.2532 - val_mse: 0.2532 - val_mae: 0.4263\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0316 - val_loss: 0.2309 - val_mse: 0.2309 - val_mae: 0.4035\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0312 - val_loss: 0.3189 - val_mse: 0.3189 - val_mae: 0.4957\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0314 - val_loss: 0.2531 - val_mse: 0.2531 - val_mae: 0.4248\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0312 - val_loss: 0.2753 - val_mse: 0.2753 - val_mae: 0.4521\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0316 - val_loss: 0.2396 - val_mse: 0.2396 - val_mae: 0.4120\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0314 - val_loss: 0.2711 - val_mse: 0.2711 - val_mae: 0.4443\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0311 - val_loss: 0.2932 - val_mse: 0.2932 - val_mae: 0.4680\n",
            "The relative test RMS error is 0.293204\n",
            "The relative test MAE is 0.468045\n",
            "The relative test RMS error for the updated dataset is 0.005884\n",
            "The relative train RMS error is 0.002528\n",
            "The relative train MAE is 0.031101\n",
            "The relative train RMS error for the updated dataset is 0.004916\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 15ms/step - loss: 0.1069 - mse: 0.1069 - mae: 0.1849 - val_loss: 0.3504 - val_mse: 0.3504 - val_mae: 0.5574\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0482 - val_loss: 0.2160 - val_mse: 0.2160 - val_mae: 0.4291\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0411 - val_loss: 0.1465 - val_mse: 0.1465 - val_mae: 0.3488\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0390 - val_loss: 0.1061 - val_mse: 0.1061 - val_mae: 0.2982\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0366 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.2323\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0352 - val_loss: 0.0544 - val_mse: 0.0544 - val_mae: 0.2087\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0326 - val_loss: 0.0425 - val_mse: 0.0425 - val_mae: 0.1804\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0322 - val_loss: 0.0287 - val_mse: 0.0287 - val_mae: 0.1410\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0310 - val_loss: 0.0319 - val_mse: 0.0319 - val_mae: 0.1539\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0299 - val_loss: 0.0369 - val_mse: 0.0369 - val_mae: 0.1706\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0289 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1210\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0282 - val_loss: 0.0251 - val_mse: 0.0251 - val_mae: 0.1339\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0265 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1304\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0275 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1271\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0260 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1270\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0256 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.1203\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0250 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.1119\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0256 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1256\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0246 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.1082\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0248 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.1096\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0246 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.1136\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0236 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1318\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0232 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1223\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0237 - val_loss: 0.0179 - val_mse: 0.0179 - val_mae: 0.1152\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0233 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.1149\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0226 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.1098\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0227 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1148\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0229 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.1020\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0225 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.1226\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0227 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0933\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0226 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.1020\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0225 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0831\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0228 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0930\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0224 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0963\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0229 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0889\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0226 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0985\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0225 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0903\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0223 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0868\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0226 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.1011\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0230 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.1015\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0224 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0840\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0224 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0834\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0225 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0759\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0229 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0793\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0222 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0836\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0225 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0827\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0225 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0913\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0222 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0596\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0228 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0817\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0227 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0899\n",
            "The relative test RMS error is 0.011469\n",
            "The relative test MAE is 0.089876\n",
            "The relative test RMS error for the updated dataset is 0.002956\n",
            "The relative train RMS error is 0.001294\n",
            "The relative train MAE is 0.022696\n",
            "The relative train RMS error for the updated dataset is 0.001655\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 14ms/step - loss: 0.1222 - mse: 0.1222 - mae: 0.2014 - val_loss: 0.4860 - val_mse: 0.4860 - val_mae: 0.5513\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0720 - val_loss: 0.3232 - val_mse: 0.3232 - val_mae: 0.4500\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0642 - val_loss: 0.2288 - val_mse: 0.2288 - val_mae: 0.3689\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0589 - val_loss: 0.2075 - val_mse: 0.2075 - val_mae: 0.3704\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0541 - val_loss: 0.1367 - val_mse: 0.1367 - val_mae: 0.2901\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0515 - val_loss: 0.1186 - val_mse: 0.1186 - val_mae: 0.2749\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0475 - val_loss: 0.0919 - val_mse: 0.0919 - val_mae: 0.2398\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0475 - val_loss: 0.0734 - val_mse: 0.0734 - val_mae: 0.2099\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0454 - val_loss: 0.0584 - val_mse: 0.0584 - val_mae: 0.1808\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0447 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.1963\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0430 - val_loss: 0.0432 - val_mse: 0.0432 - val_mae: 0.1516\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0440 - val_loss: 0.0633 - val_mse: 0.0633 - val_mae: 0.2007\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0418 - val_loss: 0.0563 - val_mse: 0.0563 - val_mae: 0.1876\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0423 - val_loss: 0.0437 - val_mse: 0.0437 - val_mae: 0.1571\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0422 - val_loss: 0.0426 - val_mse: 0.0426 - val_mae: 0.1559\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0416 - val_loss: 0.0496 - val_mse: 0.0496 - val_mae: 0.1775\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0415 - val_loss: 0.0419 - val_mse: 0.0419 - val_mae: 0.1567\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0424 - val_loss: 0.0474 - val_mse: 0.0474 - val_mae: 0.1726\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0415 - val_loss: 0.0350 - val_mse: 0.0350 - val_mae: 0.1387\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0410 - val_loss: 0.0353 - val_mse: 0.0353 - val_mae: 0.1418\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0414 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1374\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0410 - val_loss: 0.0381 - val_mse: 0.0381 - val_mae: 0.1483\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0418 - val_loss: 0.0361 - val_mse: 0.0361 - val_mae: 0.1429\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0402 - val_loss: 0.0353 - val_mse: 0.0353 - val_mae: 0.1397\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0409 - val_loss: 0.0360 - val_mse: 0.0360 - val_mae: 0.1446\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0408 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1764\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0415 - val_loss: 0.0380 - val_mse: 0.0380 - val_mae: 0.1491\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0407 - val_loss: 0.0363 - val_mse: 0.0363 - val_mae: 0.1446\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0415 - val_loss: 0.0363 - val_mse: 0.0363 - val_mae: 0.1450\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0407 - val_loss: 0.0357 - val_mse: 0.0357 - val_mae: 0.1416\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0416 - val_loss: 0.0439 - val_mse: 0.0439 - val_mae: 0.1649\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0410 - val_loss: 0.0387 - val_mse: 0.0387 - val_mae: 0.1502\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0404 - val_loss: 0.0382 - val_mse: 0.0382 - val_mae: 0.1512\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0412 - val_loss: 0.0362 - val_mse: 0.0362 - val_mae: 0.1423\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0407 - val_loss: 0.0375 - val_mse: 0.0375 - val_mae: 0.1472\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0407 - val_loss: 0.0346 - val_mse: 0.0346 - val_mae: 0.1381\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0410 - val_loss: 0.0422 - val_mse: 0.0422 - val_mae: 0.1588\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0410 - val_loss: 0.0382 - val_mse: 0.0382 - val_mae: 0.1495\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0411 - val_loss: 0.0404 - val_mse: 0.0404 - val_mae: 0.1527\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0408 - val_loss: 0.0407 - val_mse: 0.0407 - val_mae: 0.1551\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0408 - val_loss: 0.0339 - val_mse: 0.0339 - val_mae: 0.1363\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0414 - val_loss: 0.0333 - val_mse: 0.0333 - val_mae: 0.1356\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0407 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.1331\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0405 - val_loss: 0.0405 - val_mse: 0.0405 - val_mae: 0.1524\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0417 - val_loss: 0.0319 - val_mse: 0.0319 - val_mae: 0.1308\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0404 - val_loss: 0.0428 - val_mse: 0.0428 - val_mae: 0.1605\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0403 - val_loss: 0.0372 - val_mse: 0.0372 - val_mae: 0.1444\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0405 - val_loss: 0.0344 - val_mse: 0.0344 - val_mae: 0.1358\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0414 - val_loss: 0.0317 - val_mse: 0.0317 - val_mae: 0.1305\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0403 - val_loss: 0.0327 - val_mse: 0.0327 - val_mae: 0.1333\n",
            "The relative test RMS error is 0.032659\n",
            "The relative test MAE is 0.133300\n",
            "The relative test RMS error for the updated dataset is 0.010817\n",
            "The relative train RMS error is 0.003502\n",
            "The relative train MAE is 0.040296\n",
            "The relative train RMS error for the updated dataset is 0.005436\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 5s 15ms/step - loss: 0.1178 - mse: 0.1178 - mae: 0.1920 - val_loss: 6.9452 - val_mse: 6.9452 - val_mae: 2.4737\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0474 - val_loss: 4.0237 - val_mse: 4.0237 - val_mae: 1.8636\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0428 - val_loss: 2.9789 - val_mse: 2.9789 - val_mae: 1.6136\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0409 - val_loss: 2.5663 - val_mse: 2.5663 - val_mae: 1.4861\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0384 - val_loss: 2.2605 - val_mse: 2.2605 - val_mae: 1.3854\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0372 - val_loss: 2.0092 - val_mse: 2.0092 - val_mae: 1.2973\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0350 - val_loss: 1.8057 - val_mse: 1.8057 - val_mae: 1.2205\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0341 - val_loss: 1.6578 - val_mse: 1.6578 - val_mae: 1.1634\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0329 - val_loss: 1.5940 - val_mse: 1.5940 - val_mae: 1.1437\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0315 - val_loss: 1.4752 - val_mse: 1.4752 - val_mae: 1.0947\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0304 - val_loss: 1.3841 - val_mse: 1.3841 - val_mae: 1.0563\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0297 - val_loss: 1.2977 - val_mse: 1.2977 - val_mae: 1.0197\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0280 - val_loss: 1.2372 - val_mse: 1.2372 - val_mae: 0.9961\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0274 - val_loss: 1.1890 - val_mse: 1.1890 - val_mae: 0.9769\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0268 - val_loss: 1.1311 - val_mse: 1.1311 - val_mae: 0.9551\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0272 - val_loss: 1.0692 - val_mse: 1.0692 - val_mae: 0.9241\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0262 - val_loss: 1.0559 - val_mse: 1.0559 - val_mae: 0.9251\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0255 - val_loss: 1.0026 - val_mse: 1.0026 - val_mae: 0.8989\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0253 - val_loss: 0.9378 - val_mse: 0.9378 - val_mae: 0.8642\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0251 - val_loss: 0.8819 - val_mse: 0.8819 - val_mae: 0.8334\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0255 - val_loss: 0.8580 - val_mse: 0.8580 - val_mae: 0.8227\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0244 - val_loss: 0.8756 - val_mse: 0.8756 - val_mae: 0.8379\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0243 - val_loss: 0.8111 - val_mse: 0.8111 - val_mae: 0.8005\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0234 - val_loss: 0.7994 - val_mse: 0.7994 - val_mae: 0.7949\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0237 - val_loss: 0.7762 - val_mse: 0.7762 - val_mae: 0.7831\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0235 - val_loss: 0.7700 - val_mse: 0.7700 - val_mae: 0.7807\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0237 - val_loss: 0.7590 - val_mse: 0.7590 - val_mae: 0.7756\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0235 - val_loss: 0.7249 - val_mse: 0.7249 - val_mae: 0.7552\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0231 - val_loss: 0.7441 - val_mse: 0.7441 - val_mae: 0.7698\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0233 - val_loss: 0.6599 - val_mse: 0.6599 - val_mae: 0.7161\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0230 - val_loss: 0.7114 - val_mse: 0.7114 - val_mae: 0.7532\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0228 - val_loss: 0.6155 - val_mse: 0.6155 - val_mae: 0.6851\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0229 - val_loss: 0.6467 - val_mse: 0.6467 - val_mae: 0.7104\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0230 - val_loss: 0.6067 - val_mse: 0.6067 - val_mae: 0.6847\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0234 - val_loss: 0.6223 - val_mse: 0.6223 - val_mae: 0.6945\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0225 - val_loss: 0.6129 - val_mse: 0.6129 - val_mae: 0.6896\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0230 - val_loss: 0.6077 - val_mse: 0.6077 - val_mae: 0.6893\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0222 - val_loss: 0.5501 - val_mse: 0.5501 - val_mae: 0.6462\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0226 - val_loss: 0.5451 - val_mse: 0.5451 - val_mae: 0.6438\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0227 - val_loss: 0.6429 - val_mse: 0.6429 - val_mae: 0.7183\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0223 - val_loss: 0.5446 - val_mse: 0.5446 - val_mae: 0.6467\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0223 - val_loss: 0.5106 - val_mse: 0.5106 - val_mae: 0.6191\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0224 - val_loss: 0.5157 - val_mse: 0.5157 - val_mae: 0.6253\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0231 - val_loss: 0.4913 - val_mse: 0.4913 - val_mae: 0.6068\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0222 - val_loss: 0.5137 - val_mse: 0.5137 - val_mae: 0.6276\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0220 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.5900\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0219 - val_loss: 0.5104 - val_mse: 0.5104 - val_mae: 0.6252\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0223 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.5754\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0220 - val_loss: 0.5149 - val_mse: 0.5149 - val_mae: 0.6311\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0222 - val_loss: 0.5204 - val_mse: 0.5204 - val_mae: 0.6383\n",
            "The relative test RMS error is 0.520403\n",
            "The relative test MAE is 0.638264\n",
            "The relative test RMS error for the updated dataset is 0.006550\n",
            "The relative train RMS error is 0.001350\n",
            "The relative train MAE is 0.022165\n",
            "The relative train RMS error for the updated dataset is 0.003022\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 15ms/step - loss: 0.1430 - mse: 0.1430 - mae: 0.2216 - val_loss: 0.8667 - val_mse: 0.8667 - val_mae: 0.5771\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0951 - val_loss: 0.4932 - val_mse: 0.4932 - val_mae: 0.4360\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0828 - val_loss: 0.3714 - val_mse: 0.3714 - val_mae: 0.3758\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0756 - val_loss: 0.2857 - val_mse: 0.2857 - val_mae: 0.3287\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0707 - val_loss: 0.2335 - val_mse: 0.2335 - val_mae: 0.2964\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0675 - val_loss: 0.1969 - val_mse: 0.1969 - val_mae: 0.2703\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0631 - val_loss: 0.1802 - val_mse: 0.1802 - val_mae: 0.2590\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0618 - val_loss: 0.1541 - val_mse: 0.1541 - val_mae: 0.2369\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0601 - val_loss: 0.1407 - val_mse: 0.1407 - val_mae: 0.2265\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0595 - val_loss: 0.1348 - val_mse: 0.1348 - val_mae: 0.2229\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0585 - val_loss: 0.1234 - val_mse: 0.1234 - val_mae: 0.2129\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0590 - val_loss: 0.1239 - val_mse: 0.1239 - val_mae: 0.2145\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0575 - val_loss: 0.1179 - val_mse: 0.1179 - val_mae: 0.2103\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0578 - val_loss: 0.1015 - val_mse: 0.1015 - val_mae: 0.1917\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0572 - val_loss: 0.1153 - val_mse: 0.1153 - val_mae: 0.2084\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0569 - val_loss: 0.0999 - val_mse: 0.0999 - val_mae: 0.1919\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0570 - val_loss: 0.0967 - val_mse: 0.0967 - val_mae: 0.1881\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0565 - val_loss: 0.0966 - val_mse: 0.0966 - val_mae: 0.1885\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0558 - val_loss: 0.0977 - val_mse: 0.0977 - val_mae: 0.1908\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0567 - val_loss: 0.1006 - val_mse: 0.1006 - val_mae: 0.1945\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0568 - val_loss: 0.0944 - val_mse: 0.0944 - val_mae: 0.1887\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0564 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.1862\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0570 - val_loss: 0.0907 - val_mse: 0.0907 - val_mae: 0.1838\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0561 - val_loss: 0.0873 - val_mse: 0.0873 - val_mae: 0.1812\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0563 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.1783\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0574 - val_loss: 0.0909 - val_mse: 0.0909 - val_mae: 0.1883\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0564 - val_loss: 0.0890 - val_mse: 0.0890 - val_mae: 0.1847\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0564 - val_loss: 0.0937 - val_mse: 0.0937 - val_mae: 0.1912\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0567 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.1807\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0576 - val_loss: 0.0757 - val_mse: 0.0757 - val_mae: 0.1704\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0566 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.1841\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0563 - val_loss: 0.0778 - val_mse: 0.0778 - val_mae: 0.1733\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0559 - val_loss: 0.0918 - val_mse: 0.0918 - val_mae: 0.1921\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0565 - val_loss: 0.0835 - val_mse: 0.0835 - val_mae: 0.1811\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0562 - val_loss: 0.0720 - val_mse: 0.0720 - val_mae: 0.1662\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0564 - val_loss: 0.0784 - val_mse: 0.0784 - val_mae: 0.1742\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0565 - val_loss: 0.0773 - val_mse: 0.0773 - val_mae: 0.1724\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0566 - val_loss: 0.0803 - val_mse: 0.0803 - val_mae: 0.1751\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0562 - val_loss: 0.0826 - val_mse: 0.0826 - val_mae: 0.1779\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0561 - val_loss: 0.0823 - val_mse: 0.0823 - val_mae: 0.1771\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0559 - val_loss: 0.0885 - val_mse: 0.0885 - val_mae: 0.1832\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0563 - val_loss: 0.0796 - val_mse: 0.0796 - val_mae: 0.1723\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0562 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.1784\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0562 - val_loss: 0.0897 - val_mse: 0.0897 - val_mae: 0.1825\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0561 - val_loss: 0.0928 - val_mse: 0.0928 - val_mae: 0.1850\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0562 - val_loss: 0.0991 - val_mse: 0.0991 - val_mae: 0.1917\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0563 - val_loss: 0.1045 - val_mse: 0.1045 - val_mae: 0.1968\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0563 - val_loss: 0.1041 - val_mse: 0.1041 - val_mae: 0.1915\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0565 - val_loss: 0.1118 - val_mse: 0.1118 - val_mae: 0.1969\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0560 - val_loss: 0.1090 - val_mse: 0.1090 - val_mae: 0.1969\n",
            "The relative test RMS error is 0.108972\n",
            "The relative test MAE is 0.196882\n",
            "The relative test RMS error for the updated dataset is 4.925305\n",
            "The relative train RMS error is 0.005853\n",
            "The relative train MAE is 0.055954\n",
            "The relative train RMS error for the updated dataset is 0.050669\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 5s 15ms/step - loss: 0.1493 - mse: 0.1493 - mae: 0.2352 - val_loss: 0.3744 - val_mse: 0.3744 - val_mae: 0.4864\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.0999 - val_loss: 0.2290 - val_mse: 0.2290 - val_mae: 0.3793\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0852 - val_loss: 0.1433 - val_mse: 0.1433 - val_mae: 0.2978\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0757 - val_loss: 0.1024 - val_mse: 0.1024 - val_mae: 0.2549\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0710 - val_loss: 0.0734 - val_mse: 0.0734 - val_mae: 0.2151\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0684 - val_loss: 0.0615 - val_mse: 0.0615 - val_mae: 0.1963\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0637 - val_loss: 0.0556 - val_mse: 0.0556 - val_mae: 0.1867\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0636 - val_loss: 0.0452 - val_mse: 0.0452 - val_mae: 0.1673\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0625 - val_loss: 0.0410 - val_mse: 0.0410 - val_mae: 0.1579\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0614 - val_loss: 0.0507 - val_mse: 0.0507 - val_mae: 0.1830\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0614 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1793\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0605 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1759\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0596 - val_loss: 0.0430 - val_mse: 0.0430 - val_mae: 0.1678\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0598 - val_loss: 0.0331 - val_mse: 0.0331 - val_mae: 0.1413\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0582 - val_loss: 0.0384 - val_mse: 0.0384 - val_mae: 0.1563\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0598 - val_loss: 0.0356 - val_mse: 0.0356 - val_mae: 0.1496\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0589 - val_loss: 0.0379 - val_mse: 0.0379 - val_mae: 0.1556\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0591 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1604\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0589 - val_loss: 0.0398 - val_mse: 0.0398 - val_mae: 0.1611\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0589 - val_loss: 0.0327 - val_mse: 0.0327 - val_mae: 0.1415\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0587 - val_loss: 0.0352 - val_mse: 0.0352 - val_mae: 0.1491\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0591 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1358\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0595 - val_loss: 0.0338 - val_mse: 0.0338 - val_mae: 0.1447\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0588 - val_loss: 0.0357 - val_mse: 0.0357 - val_mae: 0.1493\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0585 - val_loss: 0.0374 - val_mse: 0.0374 - val_mae: 0.1545\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0593 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1601\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0592 - val_loss: 0.0352 - val_mse: 0.0352 - val_mae: 0.1496\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0586 - val_loss: 0.0334 - val_mse: 0.0334 - val_mae: 0.1445\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0585 - val_loss: 0.0388 - val_mse: 0.0388 - val_mae: 0.1600\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0593 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1420\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0588 - val_loss: 0.0269 - val_mse: 0.0269 - val_mae: 0.1248\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0584 - val_loss: 0.0297 - val_mse: 0.0297 - val_mae: 0.1341\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0586 - val_loss: 0.0417 - val_mse: 0.0417 - val_mae: 0.1681\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0592 - val_loss: 0.0403 - val_mse: 0.0403 - val_mae: 0.1649\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0585 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1352\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0588 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1359\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0585 - val_loss: 0.0286 - val_mse: 0.0286 - val_mae: 0.1315\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0582 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1289\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0578 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1456\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0580 - val_loss: 0.0255 - val_mse: 0.0255 - val_mae: 0.1225\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0583 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1248\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0579 - val_loss: 0.0303 - val_mse: 0.0303 - val_mae: 0.1389\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0583 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1173\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0587 - val_loss: 0.0304 - val_mse: 0.0304 - val_mae: 0.1396\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0582 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1369\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0579 - val_loss: 0.0316 - val_mse: 0.0316 - val_mae: 0.1431\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0583 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1191\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0578 - val_loss: 0.0274 - val_mse: 0.0274 - val_mae: 0.1300\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0588 - val_loss: 0.0259 - val_mse: 0.0259 - val_mae: 0.1259\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0574 - val_loss: 0.0271 - val_mse: 0.0271 - val_mae: 0.1308\n",
            "The relative test RMS error is 0.027102\n",
            "The relative test MAE is 0.130758\n",
            "The relative test RMS error for the updated dataset is 0.021609\n",
            "The relative train RMS error is 0.006177\n",
            "The relative train MAE is 0.057408\n",
            "The relative train RMS error for the updated dataset is 6.856708\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 15ms/step - loss: 0.1622 - mse: 0.1622 - mae: 0.2362 - val_loss: 3.2676 - val_mse: 3.2676 - val_mae: 1.6271\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1031 - val_loss: 1.5455 - val_mse: 1.5455 - val_mae: 1.0474\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0891 - val_loss: 0.8706 - val_mse: 0.8706 - val_mae: 0.7726\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0795 - val_loss: 0.6775 - val_mse: 0.6775 - val_mae: 0.6849\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0739 - val_loss: 0.5786 - val_mse: 0.5786 - val_mae: 0.6239\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0696 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.5717\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0647 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.5352\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0638 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4946\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0622 - val_loss: 0.3449 - val_mse: 0.3449 - val_mae: 0.4590\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0602 - val_loss: 0.3227 - val_mse: 0.3227 - val_mae: 0.4426\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0595 - val_loss: 0.2894 - val_mse: 0.2894 - val_mae: 0.4175\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0590 - val_loss: 0.2873 - val_mse: 0.2873 - val_mae: 0.4190\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0579 - val_loss: 0.2564 - val_mse: 0.2564 - val_mae: 0.3925\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0575 - val_loss: 0.2137 - val_mse: 0.2137 - val_mae: 0.3565\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0565 - val_loss: 0.2250 - val_mse: 0.2250 - val_mae: 0.3669\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0567 - val_loss: 0.2371 - val_mse: 0.2371 - val_mae: 0.3800\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0565 - val_loss: 0.2191 - val_mse: 0.2191 - val_mae: 0.3637\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0566 - val_loss: 0.2685 - val_mse: 0.2685 - val_mae: 0.4212\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0563 - val_loss: 0.2013 - val_mse: 0.2013 - val_mae: 0.3474\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0561 - val_loss: 0.1865 - val_mse: 0.1865 - val_mae: 0.3327\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0564 - val_loss: 0.2011 - val_mse: 0.2011 - val_mae: 0.3510\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0558 - val_loss: 0.1758 - val_mse: 0.1758 - val_mae: 0.3224\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0563 - val_loss: 0.1746 - val_mse: 0.1746 - val_mae: 0.3214\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0562 - val_loss: 0.1676 - val_mse: 0.1676 - val_mae: 0.3145\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0561 - val_loss: 0.1966 - val_mse: 0.1966 - val_mae: 0.3486\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0560 - val_loss: 0.1825 - val_mse: 0.1825 - val_mae: 0.3331\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0560 - val_loss: 0.1559 - val_mse: 0.1559 - val_mae: 0.3026\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0556 - val_loss: 0.1588 - val_mse: 0.1588 - val_mae: 0.3093\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0558 - val_loss: 0.1604 - val_mse: 0.1604 - val_mae: 0.3114\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0562 - val_loss: 0.1523 - val_mse: 0.1523 - val_mae: 0.3046\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0562 - val_loss: 0.1507 - val_mse: 0.1507 - val_mae: 0.3030\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0556 - val_loss: 0.1279 - val_mse: 0.1279 - val_mae: 0.2734\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0558 - val_loss: 0.1611 - val_mse: 0.1611 - val_mae: 0.3198\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0566 - val_loss: 0.1598 - val_mse: 0.1598 - val_mae: 0.3244\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0555 - val_loss: 0.1406 - val_mse: 0.1406 - val_mae: 0.2941\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0559 - val_loss: 0.1220 - val_mse: 0.1220 - val_mae: 0.2699\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0561 - val_loss: 0.1107 - val_mse: 0.1107 - val_mae: 0.2533\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0562 - val_loss: 0.1228 - val_mse: 0.1228 - val_mae: 0.2746\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0552 - val_loss: 0.1493 - val_mse: 0.1493 - val_mae: 0.3099\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0555 - val_loss: 0.1114 - val_mse: 0.1114 - val_mae: 0.2587\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0558 - val_loss: 0.1294 - val_mse: 0.1294 - val_mae: 0.2855\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0556 - val_loss: 0.1107 - val_mse: 0.1107 - val_mae: 0.2563\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0555 - val_loss: 0.1024 - val_mse: 0.1024 - val_mae: 0.2451\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0558 - val_loss: 0.1313 - val_mse: 0.1313 - val_mae: 0.2878\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0559 - val_loss: 0.1135 - val_mse: 0.1135 - val_mae: 0.2601\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0557 - val_loss: 0.1187 - val_mse: 0.1187 - val_mae: 0.2676\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0552 - val_loss: 0.0943 - val_mse: 0.0943 - val_mae: 0.2331\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0555 - val_loss: 0.1196 - val_mse: 0.1196 - val_mae: 0.2690\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0559 - val_loss: 0.1220 - val_mse: 0.1220 - val_mae: 0.2701\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0552 - val_loss: 0.1451 - val_mse: 0.1451 - val_mae: 0.3041\n",
            "The relative test RMS error is 0.145113\n",
            "The relative test MAE is 0.304079\n",
            "The relative test RMS error for the updated dataset is 0.007562\n",
            "The relative train RMS error is 0.005735\n",
            "The relative train MAE is 0.055247\n",
            "The relative train RMS error for the updated dataset is 2.888006\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 16ms/step - loss: 0.1585 - mse: 0.1585 - mae: 0.1914 - val_loss: 1.9552 - val_mse: 1.9552 - val_mae: 1.2495\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0419 - val_loss: 1.5200 - val_mse: 1.5200 - val_mae: 1.0709\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0338 - val_loss: 1.2707 - val_mse: 1.2707 - val_mae: 0.9698\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0326 - val_loss: 1.0179 - val_mse: 1.0179 - val_mae: 0.8572\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0309 - val_loss: 0.7810 - val_mse: 0.7810 - val_mae: 0.7278\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0303 - val_loss: 0.6228 - val_mse: 0.6228 - val_mae: 0.6340\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0293 - val_loss: 0.5703 - val_mse: 0.5703 - val_mae: 0.6081\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0296 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.5389\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0290 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5617\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0280 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.5026\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0271 - val_loss: 0.3600 - val_mse: 0.3600 - val_mae: 0.4824\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0273 - val_loss: 0.3665 - val_mse: 0.3665 - val_mae: 0.5073\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0258 - val_loss: 0.2717 - val_mse: 0.2717 - val_mae: 0.4062\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0260 - val_loss: 0.2688 - val_mse: 0.2688 - val_mae: 0.4162\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0249 - val_loss: 0.2707 - val_mse: 0.2707 - val_mae: 0.4263\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0251 - val_loss: 0.2023 - val_mse: 0.2023 - val_mae: 0.3481\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0243 - val_loss: 0.2695 - val_mse: 0.2695 - val_mae: 0.4442\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0238 - val_loss: 0.2013 - val_mse: 0.2013 - val_mae: 0.3622\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0233 - val_loss: 0.1725 - val_mse: 0.1725 - val_mae: 0.3259\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0229 - val_loss: 0.1650 - val_mse: 0.1650 - val_mae: 0.3217\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0234 - val_loss: 0.1520 - val_mse: 0.1520 - val_mae: 0.3034\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0219 - val_loss: 0.1489 - val_mse: 0.1489 - val_mae: 0.3049\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0222 - val_loss: 0.1664 - val_mse: 0.1664 - val_mae: 0.3364\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0220 - val_loss: 0.1294 - val_mse: 0.1294 - val_mae: 0.2803\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0212 - val_loss: 0.1495 - val_mse: 0.1495 - val_mae: 0.3149\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0217 - val_loss: 0.1352 - val_mse: 0.1352 - val_mae: 0.2966\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0223 - val_loss: 0.1175 - val_mse: 0.1175 - val_mae: 0.2692\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0206 - val_loss: 0.1666 - val_mse: 0.1666 - val_mae: 0.3462\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0207 - val_loss: 0.1253 - val_mse: 0.1253 - val_mae: 0.2874\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 0.1130 - val_mse: 0.1130 - val_mae: 0.2694\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0208 - val_loss: 0.1272 - val_mse: 0.1272 - val_mae: 0.2922\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0205 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2242\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 0.0942 - val_mse: 0.0942 - val_mae: 0.2413\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0212 - val_loss: 0.0945 - val_mse: 0.0945 - val_mae: 0.2409\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0203 - val_loss: 0.0925 - val_mse: 0.0925 - val_mae: 0.2395\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0196 - val_loss: 0.0844 - val_mse: 0.0844 - val_mae: 0.2263\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0201 - val_loss: 0.0781 - val_mse: 0.0781 - val_mae: 0.2182\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0202 - val_loss: 0.0840 - val_mse: 0.0840 - val_mae: 0.2282\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0199 - val_loss: 0.0996 - val_mse: 0.0996 - val_mae: 0.2563\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0196 - val_loss: 0.0939 - val_mse: 0.0939 - val_mae: 0.2453\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0199 - val_loss: 0.0776 - val_mse: 0.0776 - val_mae: 0.2162\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0198 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2131\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0191 - val_loss: 0.0873 - val_mse: 0.0873 - val_mae: 0.2344\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0198 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.2060\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0199 - val_loss: 0.1022 - val_mse: 0.1022 - val_mae: 0.2626\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0192 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1809\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0191 - val_loss: 0.0766 - val_mse: 0.0766 - val_mae: 0.2179\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0197 - val_loss: 0.0830 - val_mse: 0.0830 - val_mae: 0.2306\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0193 - val_loss: 0.1240 - val_mse: 0.1240 - val_mae: 0.2965\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0197 - val_loss: 0.1245 - val_mse: 0.1245 - val_mae: 0.3042\n",
            "The relative test RMS error is 0.124505\n",
            "The relative test MAE is 0.304226\n",
            "The relative test RMS error for the updated dataset is 0.005879\n",
            "The relative train RMS error is 0.001435\n",
            "The relative train MAE is 0.019702\n",
            "The relative train RMS error for the updated dataset is 0.002434\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "diz = {}\n",
        "diz['stock'] = []\n",
        "diz['roi'] = []\n",
        "diz['gain'] = []\n",
        "diz['initial_investment'] = []\n",
        "diz['RMS_train'] = []\n",
        "diz['RMS'] = []\n",
        "\n",
        "\n",
        "\n",
        "for stock in stock_list_exam:\n",
        "  # scarico i dati\n",
        "  df = yf.download(stock, start, end)\n",
        "\n",
        "  split = 0.8967\n",
        "  index = int(len(df)*split)\n",
        "  values = df.iloc[index:].shape[0]\n",
        "  # creo il modello\n",
        "  LSTM_1 = LSTM_Model(tickerSymbol = stock , start = start, end = end, depth = 0, epochs=50, values=252, naive = True, verbose = True, train_test_split=0.8747)\n",
        "  LSTM_1.full_workflow_and_plot()\n",
        "\n",
        "  error = LSTM_1.RMS_error\n",
        "  error_train = LSTM_1.RMS_error_train\n",
        "\n",
        "  xt, yt, pred, pred_update = LSTM_1.get_predicted_values()\n",
        "  df_test = df[index:index+pred.shape[0]].copy()\n",
        "\n",
        "  pred_r = pd.Series(pred.reshape(-1), index=df_test.index)\n",
        "  df_test['pred'] = pred_r\n",
        "\n",
        "  mean_open = df[:index].Open.mean()\n",
        "  std_open = df[:index].Open.std()\n",
        "\n",
        "  open_norm = (df_test.Open - mean_open) / std_open\n",
        "  df_test['open_norm'] = open_norm\n",
        "  df_test['operation'] = np.where(df_test['pred'] > df_test['open_norm'], 1, 0 )\n",
        "  tot, stats = calculate_investment(df_test,df_test.Open.iloc[0])\n",
        "\n",
        "  roi = (tot - df_test.Open.iloc[0])/ df_test.Open.iloc[0]\n",
        "\n",
        "  diz['stock'].append(stock)\n",
        "  diz['initial_investment'].append(df_test.Open.iloc[0])\n",
        "  diz['roi'].append(roi)\n",
        "  diz['gain'].append(tot)\n",
        "  diz['RMS_train'].append(error_train)\n",
        "  diz['RMS'].append(error)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lnG99c62GINL",
        "outputId": "78f317fc-28b0-42e7-8472-5207a0862255"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   stock       roi           gain  initial_investment  RMS_train       RMS\n",
              "0    NEE  0.159492      91.066501           78.540001   0.000944  0.009159\n",
              "1  BRK-A  0.173268  472579.320509       402789.000000   0.001469  0.140547\n",
              "2    UPS  0.181034     211.192570          178.820007   0.002528  0.293204\n",
              "3    JNJ  0.183773     186.834886          157.830002   0.001294  0.011469\n",
              "4    NGG  0.212837      74.346937           61.299999   0.003502  0.032659\n",
              "5   GOOG  0.242602     141.355949          113.758003   0.001350  0.520403\n",
              "6    XOM  0.376176      77.630067           56.410000   0.005853  0.108972\n",
              "7    BHP  0.400629      88.898062           63.470116   0.006177  0.027102\n",
              "8    RIO  0.492286     119.382843           80.000000   0.005735  0.145113\n",
              "9   AAPL  0.687599     227.724555          134.940002   0.001435  0.124505"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bddc2b1-eb28-419f-acbf-8ec09e3340f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>roi</th>\n",
              "      <th>gain</th>\n",
              "      <th>initial_investment</th>\n",
              "      <th>RMS_train</th>\n",
              "      <th>RMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEE</td>\n",
              "      <td>0.159492</td>\n",
              "      <td>91.066501</td>\n",
              "      <td>78.540001</td>\n",
              "      <td>0.000944</td>\n",
              "      <td>0.009159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BRK-A</td>\n",
              "      <td>0.173268</td>\n",
              "      <td>472579.320509</td>\n",
              "      <td>402789.000000</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>0.140547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UPS</td>\n",
              "      <td>0.181034</td>\n",
              "      <td>211.192570</td>\n",
              "      <td>178.820007</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>0.293204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JNJ</td>\n",
              "      <td>0.183773</td>\n",
              "      <td>186.834886</td>\n",
              "      <td>157.830002</td>\n",
              "      <td>0.001294</td>\n",
              "      <td>0.011469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NGG</td>\n",
              "      <td>0.212837</td>\n",
              "      <td>74.346937</td>\n",
              "      <td>61.299999</td>\n",
              "      <td>0.003502</td>\n",
              "      <td>0.032659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GOOG</td>\n",
              "      <td>0.242602</td>\n",
              "      <td>141.355949</td>\n",
              "      <td>113.758003</td>\n",
              "      <td>0.001350</td>\n",
              "      <td>0.520403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XOM</td>\n",
              "      <td>0.376176</td>\n",
              "      <td>77.630067</td>\n",
              "      <td>56.410000</td>\n",
              "      <td>0.005853</td>\n",
              "      <td>0.108972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BHP</td>\n",
              "      <td>0.400629</td>\n",
              "      <td>88.898062</td>\n",
              "      <td>63.470116</td>\n",
              "      <td>0.006177</td>\n",
              "      <td>0.027102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RIO</td>\n",
              "      <td>0.492286</td>\n",
              "      <td>119.382843</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.005735</td>\n",
              "      <td>0.145113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.687599</td>\n",
              "      <td>227.724555</td>\n",
              "      <td>134.940002</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.124505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bddc2b1-eb28-419f-acbf-8ec09e3340f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bddc2b1-eb28-419f-acbf-8ec09e3340f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bddc2b1-eb28-419f-acbf-8ec09e3340f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "pd.DataFrame(diz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "2-WoqBJh4ejZ",
        "outputId": "0cff09ef-ed33-4d3a-d18e-5ea8fb08d8ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'RMS error')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "plt.bar(diz['stock'],diz['RMS'])\n",
        "#plt.bar(diz['stock'],diz['RMS_train'])\n",
        "plt.xlabel('Stock')\n",
        "plt.ylabel('RMS error')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock = 'AAPL'\n",
        "start = '2010-01-01'\n",
        "end = '2022-08-01'"
      ],
      "metadata": {
        "id": "tN8Fl_vkdcGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = yf.download(stock, start, end)\n",
        "\n",
        "split = 0.8967\n",
        "index = int(len(df)*split)\n",
        "values = df.iloc[index:].shape[0]\n",
        "# creo il modello\n",
        "LSTM_1 = LSTM_Model(tickerSymbol = stock , start = start, end = end, depth = 0, epochs=50, values=252, naive = True, verbose = True, train_test_split=0.8747)\n",
        "LSTM_1.full_workflow()\n",
        "\n",
        "xt, yt, pred, pred_update = LSTM_1.get_predicted_values()\n",
        "df_test = df[index:index+pred.shape[0]].copy()\n",
        "\n",
        "pred_r = pd.Series(pred.reshape(-1), index=df_test.index)\n",
        "df_test['pred'] = pred_r\n",
        "\n",
        "mean_open = df[:index].Open.mean()\n",
        "std_open = df[:index].Open.std()\n",
        "\n",
        "open_norm = (df_test.Open - mean_open) / std_open\n",
        "df_test['open_norm'] = open_norm\n",
        "df_test['operation'] = np.where(df_test['pred'] > df_test['open_norm'], 1, 0 )\n",
        "initial_investment = df_test.Open.iloc[0]\n",
        "\n",
        "tot, stats = calculate_investment(df_test,initial_investment)\n",
        "\n",
        "\n",
        "\n",
        "roi = (tot - initial_investment)/ initial_investment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD3FqTPPdaQn",
        "outputId": "f42d93ee-0bcf-4739-a7b5-f0bd7c17b249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 4s 14ms/step - loss: 0.1585 - mse: 0.1585 - mae: 0.1914 - val_loss: 1.9552 - val_mse: 1.9552 - val_mae: 1.2495\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0419 - val_loss: 1.5200 - val_mse: 1.5200 - val_mae: 1.0709\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0338 - val_loss: 1.2707 - val_mse: 1.2707 - val_mae: 0.9698\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0326 - val_loss: 1.0179 - val_mse: 1.0179 - val_mae: 0.8572\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 17ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0309 - val_loss: 0.7810 - val_mse: 0.7810 - val_mae: 0.7278\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0303 - val_loss: 0.6228 - val_mse: 0.6228 - val_mae: 0.6340\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0293 - val_loss: 0.5703 - val_mse: 0.5703 - val_mae: 0.6081\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0296 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.5389\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0290 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5617\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0280 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.5026\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0271 - val_loss: 0.3600 - val_mse: 0.3600 - val_mae: 0.4824\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0273 - val_loss: 0.3665 - val_mse: 0.3665 - val_mae: 0.5073\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0258 - val_loss: 0.2717 - val_mse: 0.2717 - val_mae: 0.4062\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0260 - val_loss: 0.2688 - val_mse: 0.2688 - val_mae: 0.4162\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0249 - val_loss: 0.2707 - val_mse: 0.2707 - val_mae: 0.4263\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0251 - val_loss: 0.2023 - val_mse: 0.2023 - val_mae: 0.3481\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0243 - val_loss: 0.2695 - val_mse: 0.2695 - val_mae: 0.4442\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0238 - val_loss: 0.2013 - val_mse: 0.2013 - val_mae: 0.3622\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0233 - val_loss: 0.1725 - val_mse: 0.1725 - val_mae: 0.3259\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0229 - val_loss: 0.1650 - val_mse: 0.1650 - val_mae: 0.3217\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0234 - val_loss: 0.1520 - val_mse: 0.1520 - val_mae: 0.3034\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0219 - val_loss: 0.1489 - val_mse: 0.1489 - val_mae: 0.3049\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0222 - val_loss: 0.1664 - val_mse: 0.1664 - val_mae: 0.3364\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0220 - val_loss: 0.1294 - val_mse: 0.1294 - val_mae: 0.2803\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0212 - val_loss: 0.1495 - val_mse: 0.1495 - val_mae: 0.3149\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0217 - val_loss: 0.1352 - val_mse: 0.1352 - val_mae: 0.2966\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0223 - val_loss: 0.1175 - val_mse: 0.1175 - val_mae: 0.2692\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0206 - val_loss: 0.1666 - val_mse: 0.1666 - val_mae: 0.3462\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0207 - val_loss: 0.1253 - val_mse: 0.1253 - val_mae: 0.2874\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 0.1130 - val_mse: 0.1130 - val_mae: 0.2694\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0208 - val_loss: 0.1272 - val_mse: 0.1272 - val_mae: 0.2922\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0205 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2242\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 0.0942 - val_mse: 0.0942 - val_mae: 0.2413\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0212 - val_loss: 0.0945 - val_mse: 0.0945 - val_mae: 0.2409\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0203 - val_loss: 0.0925 - val_mse: 0.0925 - val_mae: 0.2395\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0196 - val_loss: 0.0844 - val_mse: 0.0844 - val_mae: 0.2263\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0201 - val_loss: 0.0781 - val_mse: 0.0781 - val_mae: 0.2182\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0202 - val_loss: 0.0840 - val_mse: 0.0840 - val_mae: 0.2282\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0199 - val_loss: 0.0996 - val_mse: 0.0996 - val_mae: 0.2563\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0196 - val_loss: 0.0939 - val_mse: 0.0939 - val_mae: 0.2453\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0199 - val_loss: 0.0776 - val_mse: 0.0776 - val_mae: 0.2162\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0198 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2131\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0191 - val_loss: 0.0873 - val_mse: 0.0873 - val_mae: 0.2344\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0198 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.2060\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0199 - val_loss: 0.1022 - val_mse: 0.1022 - val_mae: 0.2626\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0192 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1809\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0191 - val_loss: 0.0766 - val_mse: 0.0766 - val_mae: 0.2179\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0197 - val_loss: 0.0830 - val_mse: 0.0830 - val_mae: 0.2306\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0193 - val_loss: 0.1240 - val_mse: 0.1240 - val_mae: 0.2965\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0197 - val_loss: 0.1245 - val_mse: 0.1245 - val_mae: 0.3042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgJwYbjMisac",
        "outputId": "fd1dba6e-5623-483e-eb1e-2b1a921fb100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6875985708348161"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats = pd.DataFrame(stats)"
      ],
      "metadata": {
        "id": "Dw5iNt7eenku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats['cash returned'].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "z4-IvtF7ex75",
        "outputId": "a7053bbf-b576-4f88-ab67-4d0e1a47e561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd36040cc50>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXicVdn48e+dfd/XJmnSNmm6r+lCKaUUZalAeVEREFmVH4oovrjhAuqrr+KrqMgmSgUUQVatCEJpS0spXdLSfUmTNPu+75NM5vz+mEmattkz6SST+3NduTI5zzOT+zDlzpn7Oc85YoxBKaWUe/FwdQBKKaWcT5O7Ukq5IU3uSinlhjS5K6WUG9LkrpRSbsjL1QEAREVFmZSUFFeHoZRS48revXurjDHRvR0bE8k9JSWFzMxMV4ehlFLjiojk93VMyzJKKeWGNLkrpZQb0uSulFJuSJO7Ukq5oQGTu4gkicgWETkqIkdE5OtnHb9fRIyIRDl+FhF5VESyReSgiCwareCVUkr1bjCzZazA/caYfSISDOwVkY3GmKMikgRcBhT0OP9KIM3xtQx40vFdKaXUeTLgyN0YU2qM2ed43AgcAxIch38DfBvoubTkOuB5Y7cTCBOReOeGrZRSqj9DqrmLSAqwENglIuuAYmPMgbNOSwAKe/xcxOk/Bj1f6y4RyRSRzMrKyiEFrZRSY0VhTQv/OlDi6jDOMeibmEQkCHgNuA97qeZ72Esyw2KMeRp4GiAjI0MXlVdKjUt/+iCX5z7KJ8Tfm4un93qzqEsMauQuIt7YE/sLxpjXgWnAFOCAiOQBicA+EYkDioGkHk9PdLQppZTbOV7WCMAP/nGIto5OF0dz2mBmywjwDHDMGPMIgDHmkDEmxhiTYoxJwV56WWSMKQM2ALc4Zs0sB+qNMaWj1wWllHINYwwnyhtJCPOnsKaVjwvqXB1St8GM3C8EvgCsEZH9jq+1/Zz/FpALZAN/BL4y8jCVUmrsqWy0UNfSwVXz7HNGcquaXBzRaQPW3I0x2wEZ4JyUHo8NcM+II1NKqTGuqyRz8fRonv8on5yKZhdHdJreoaqUUsOUVW5P7ulxwUyJCjxj5H6qqpmfv32MguoWl8SmyV0ppYbpeFkjUUG+RAb5Mi0miJzK08n9pT0F/GFrLp/4zVZOVZ3/Eb0md6WUGqbDxfXMjA8GYGpUIEW1rd0zZk6WNxHo40m71cbe/NrzHpsmd6WUGob61g5OlDeyJCUCgGkxQRgDedX2UXpWeSMXpUXjIVBQfXrkvievhi88s4uWduuoxjcmdmJSSqnxZl9BLcZARnI4YB+5A+RUNJMUHkBRbSufy0jiSGk9edUtPL4lG4A3D5ZyrLSB909Usnbu6K3MosldKaWGITOvBk8PYcHkMABSY4Lw9hQOFteRGO4PQFpsMCmRgeRUNvHesXJa2u0lGw+Bd4+UaXJXSqmxZk9eLXMmhRDgY0+jft6ezE8MY1duDanRQQBMjw0iOTKAD05WAbAkJZyoIF/8fTx572g5HZ02vD1HpzquNXellBoim81wsKiORY6STJelUyI4XFzPgaI6fLw8SI4MJCUysPv4I9cv4MmbF3PF7Dga2qzsyasZtRg1uSul1BAV17XS1mEjPTb4jPalUyKw2gwvZxYxNyEUTw/pTu7Rwb7d5ZqlU+wXYQ8V1Y9ajJrclVJqiLId89mnxQSd0Z6REoGH2Nec+fE1swFIiQoAYNHkMOxLdUFYgA+xIb6ccNzhOhq05q6UUkOUU2FP7l219S5Bvl586aKpTI0OZE5CKABJEQFEBPpwSXrMGeemx4V0L18wGjS5K6XUEOVUNhER6EN4oM85xx5YO/OMn329PNn5wKV4e565RNeMuGCezanG2mnDaxQuqmpZRimlhiinoplp0YEDn+jg4+XRXZLpkh4bTHunbdSWJtDkrpRSQ5Rd2UTqWfX2oUqPs1+MHa3SjCZ3pdSE8/O3jrHpWPmwnlvb3E5NczvTokeW3FNjgvD0kFG7qKo1d6XUhGCMIa+6hVB/b/6wLZejpQ1cOjN2yK/TtQjYrEkhI4rHz9uTH18zu/vCq7NpcldKTQgbDpRw39/3c++aNAD25dcO62Lm1qxKAnw8WXzWDUzDcfPy5BG/Rl+0LKOUmhC2ZlViDDy1NQeA5vZOjpUOvSSy7WQlF0yNxNfL09khOpUmd6WU2zPGsDOnGoB2q42pjpkuQ739P6+qmfzqFi5Oj3Z6jM6myV0p5fYKalooqW9jSYq9lHL1vEkkhvuz+9TQkvuuU/Y/EBemRjk9RmfTmrtSyu195Bi1P3T1bP7yUT7XLUqgssnCG/uKaWjrIMTPe1Cvk1PZjI+XxxmLgY1VOnJXSrk1Ywwv7SkkIcyf2ZNCePgz80iODOSGJUm0dnTyz/0lg36t3MpmpkQG4ukhA5/sYprclVJuYU9eDdkVTee0v3esgv2FdXx1TeoZd4nOTQhl9qQQXtxVMOjfkVvVxJSosT9qB03uSik3sDe/lpv+uJOHNhw+59hzO/KYHBHAZxYnntEuInxqXjxHSxtoaOsY8HdYO20UVLd0X4wd6zS5K6XGtbaOTr7ywl46Og2ZebW0dXSecbyqycLM+OBedzzqqp0X1rQM+HsKa1ux2oz7jNxFJElEtojIURE5IiJfd7T/n4gcF5GDIvKGiIT1eM4DIpItIidE5PLR7IBSamLbkVNFeYOFzy+bjMVq4+OCujOON7ZZCfTtfe5IUrh9rfXCmtYBf8+pKnvJZ+oIlx04XwYzcrcC9xtjZgHLgXtEZBawEZhjjJkHZAEPADiO3QDMBq4AnhCRsT3bXyk1bm08WkGgjyff+OR0PAQ+yqk643hzu5WgPpL75Ah7ci+qHXjknltpX71xqruM3I0xpcaYfY7HjcAxIMEY864xxuo4bSfQVdBaB7xkjLEYY04B2cBS54eulJrobDbDe8fKuTg9mqggX+YmhrHDMe0R7DNlmi19j9xDA7wJ9vMaVFnmeFljn2u4j0VDqrmLSAqwENh11qE7gLcdjxOAwh7HihxtZ7/WXSKSKSKZlZWVQwlDKaUA2F9UR2WjhU/Osi8AtmxKBAeL6rFY7XV3i9VGR6fpc+QO9tJMwQDJ3RjDRznVLE2JcF7wo2zQyV1EgoDXgPuMMQ092r+PvXTzwlB+sTHmaWNMhjEmIzp67N/Kq5Qae/7xcTE+Xh6smWFP7osmh9HeaeNIiT1FNVvsxYV+k3uEP4W1/dfcC2paKK5r5cLUSCdFPvoGldxFxBt7Yn/BGPN6j/bbgKuAzxtjjKO5GEjq8fRER5tSSjlNu9XGvw6UcNmsWEL97XeYLpxsX16g66Jqs8U+gu+rLAP2kXthTQunU9i5Psy2l3pWjINlB7oMZraMAM8Ax4wxj/RovwL4NnCNMabnZ5oNwA0i4isiU4A0YLdzw1ZKjUUt7Vbue+ljduVWD3zyCG3NqqS2pYPrFp2u+saG+JEQ5s++Avua603dI/e+53QkRQRgsdqobLRwuLie4rpzR/Ef5lQRG+I7bi6mwuBG7hcCXwDWiMh+x9da4DEgGNjoaHsKwBhzBHgZOAr8B7jHGNPZx2srpdzI7lM1/GN/Cbf9eQ/7C+sGfsKIflc1vl4eXJR2Zll3weQw9jtG7l3Jvb+Re9e89X0F9huhHnj90DnnZObVsHxq5Dn7oI5lAy4cZozZDvTWo7f6ec7PgJ+NIC6l1Dh0oLAeEfD2FP7yUT4LksIGftIw5VQ2MyUq8Jybk5Ykh/Pvg6VsPl6OOFJXfzX3ZVMjCAvw5of/PEJDm5Ud2VXUt3Z0l3rKG9oob7AwP3H0+jIa9A5VpZTTHCiqIzU6iDkJoWRXnrvOizPlVjb1uo/p9UuSmD0phK+9uJ8T5fbNOPpL7r5enly7IIHKRgs+Xh5YbYYtxyu6jx9wfAKZlzg62+GNFk3uSimnMMZwsKiO+UlhpMUEkV3e2O9FypGwWDspqGlhWi/rvAT4ePHwp+fRZLF2J+n+yjJA97ozt61IITrYl3eOlHUfO1hUj6eHMHvS+Eruup67UsopiutaqWpqZ75jhNvc3sm/D5VyuLiB71yR7tR6dUF1CzbT91IAyZH2O09PVdnvKh0ouc9JCOXZ25eQkRJBVaOF7dmn73I9UFRHWkwQ/j7j60Z7HbkrpZziYFE9APMSw0iNCQbg+28c5qmtOcPaq7Q/OY6ST29lGbCXYQJ8PKlotAAQOIjEvDo9hiBfL5IjA6lotNDW0YkxhkPF9eOu3g6a3JVSTnKkxF6+SI8LJjXGnnTrW+1L6b51qNSpvyvHsc7LlD6W3xURYkP8APD39sSrlxUh+5IU4Q9ASV0rNc3t1LV0MD0ueIQRn3+a3JVSTnGstJHU6CD8vD2JCvIhLMA+22RSqB//PlTq1Pp7TmUTcSF+/V4ojQn2BQYuyZwtMbxrMbFWihx3riaF+w8zUtfR5K6UGrYPs6uoarKXPo6WNDAz3j7CFRHSY4NJivDnq2vSOFXV3OsuScNhjGFXbg1zB5i9EuMYufd3A1NvEh2JvLC2pTu5dyX88UQvqCqlhqWto5Nb1u9memwwf7xlMWUNbcyaFNJ9/OfXzcVqM1g77SP2E+WNpMWOvLxxsqKJ4rpWvromtd/zYoc5co8N8cPbUyiqbe1emyZhHI7cNbkrpYalqLaFTpvhWGkDt6y3rzAyM/50cu+aydLabr9BvWs99JGwdtrY7JjeuDq9/wUHY7tH7kNLc54ewqQw/+7kHuLn1X1D03iiyV0pNSxduxddNS+eNw/aL5j2TO5d/H08SQjzJ3eENzXVNLdz0cObae+0MSMumPjQ/kfTMSH2kftQkzucXkys2eIzLksyoMldKTVMhY7dix68ahbhAT7sL6wjKsi313OnRgeSWzWykfuBwjqa2zuZERfMHRdOGfD8rpH7UMsyYK+7v3esgtb2TiZHanJXSk0gBdUt+Hp5EB3sy/9cO6ff2TBTowJ5dW8RxphB3czU2t7JZ57aweeWJHHLBSkAHC62z6N/5e4LCPYbuEwykuSeFBFAVZOFxrYOVoyjNdx70tkySqlhKaxtISkioDtZ95e0p0YH0dze2X1T0UDWf3iKIyUN/PGDXDo6bVQ1WThS0kBKZMCgEjucngo51NkyAFfMicPbU7BYbVqWUUpNLIU1rYOe/z3VcbNRTmVT94i6L3lVzTz5fg5RQb4U1rRy+W+3Udlgwdfbk2VTBr/NXaCvF7dckMylM2MH/Zwu06KD+PLqVB7ddHJcznEHHbkrpYbBGENhjX3kPhhdywQMNNe9tL6VG57eiY+XB3+5cylBvl7kVjbT1G6lqslyxlTLwfjJujksnzq8sspXL0nll5+Zx8UDzMoZqzS5K6WGrL61g0aLlaRBliziQ/2IDvZlX35tv+e9daiMsoY2nr9jKTPjQ/jRNbP5n2vncM38SQDMHmJyHwkfLw+uz0jC12t8LRjWRcsySqkhy6+2z5QZ7MhdRFiSEs6evP6Te2FNC0G+Xt1JvGsp3kvSownw8WTZlPF5cdMVdOSulBqyg46ZK0MZSWckR1Bc10pJL3uUdukq9Zx9cTYxPICfXzdv3C2760qa3JVSQ/ZxQS1RQT7d67AMxpIU+8XQTEdp5kRZI9c+/iFFjvnyAAU1LeP2AuZYo8ldKTVk+wvrWJAUNqQNOGbGBxPg48meUzVYrJ18/aWP2V9Yx+5TNYDjIm1tC5MHWepR/dPkrpQakvqWDnIrm1k4OXxIz/Py9GDZlAi2nazk+R35HC9rROT0mjOVTRbaOmyDruOr/mlyV0oNyf4i+4bRC5OGvjvRJTNiyK9u4Y8f5LJwchgpkYHdW+EV1tjLMzpydw5N7kqpIelaBmDOAOup92b19BgAKhotXLsggSlRgd1b5nUtRNa1E5IaGU3uSqkhya1sJjbEl5BBLgPQ0+TIAKZGB+LpIXxqXjxTowLJq27GZjMUOEbu4/V2/7FmwOQuIkkiskVEjorIERH5uqM9QkQ2ishJx/dwR7uIyKMiki0iB0Vk0Wh3QinlfMV1rd2LffWUU9nU58bUg/G1NWncd2kaUUG+TIkOpK3DRmlDG4U1LcQE++LnrdMdnWEwI3crcL8xZhawHLhHRGYB3wU2GWPSgE2OnwGuBNIcX3cBTzo9aqXUqFu//RTffOUAf99T2N1mjCG3sql7rZjhuHZhAvdemgbA1Cj7H4lTlc0U1OhMGWcaMLkbY0qNMfscjxuBY0ACsA54znHac8C1jsfrgOeN3U4gTETinR65UmpUHSqy19a//4/DzH3oHTYcKKG6uZ2GNmt3Uh6prj8SuVVNFGpyd6oh1dxFJAVYCOwCYo0xpY5DZUDX0msJQGGPpxU52s5+rbtEJFNEMisrK4cYtlJqNNlshiMl9XxqXjy3r0ghKtiXX/7nOCfKGgGYFuOc5B4T7EuwnxdHihsobWgjUZO70ww6uYtIEPAacJ8xpqHnMWMvyvW9Un8vjDFPG2MyjDEZ0dHjc9U1pdzVqepmmts7uXh6ND+4ahYPXj2LotpWfvnOCcC++YYziAgz40LYdLwCY3QapDMNKrmLiDf2xP6CMeZ1R3N5V7nF8b3C0V4MJPV4eqKjTSk1TnRNd5ybYJ/uuHp6NCtTozhQWIevlwcJYc6brjgjPpiqJvsmHrr0gPMMZraMAM8Ax4wxj/Q4tAG41fH4VuCfPdpvccyaWQ7U9yjfKKXGgQOF9fh6eZDmKL+ICH+6NYObl0/msxmJeHgMftmBgcyIO7342Hjdr3QsGsySvxcCXwAOich+R9v3gF8AL4vInUA+cL3j2FvAWiAbaAFud2rESqlR9dTWHJ7dcYoLU6Pw8jw9/vPz9uSn1851+u+bER8MgI+nB7HB/e/SpAZvwORujNkO9PVn+tJezjfAPSOMSynlAi3tVn71zglWp8fw2xsWnJffmR5rT+6J4f5O/UQw0ekdqkqpbnvza7HaDLeuSBnWHajDEejrxdSoQFKcdJFW2elOTEqpbrtya/D0EBYnD23Fx5F6/POLCNCNOJxKk7tSqtuuU9XMSQglyPf8poaZ8edvb9SJQssySikAWts7OVBYz/IpEa4ORTmBJnelFAD/OlhCe6eNi9P1pkJ3oMldKYUxhvXbT5EeG8wFUyNdHY5yAk3uSik+yq3meFkjd6xMGdK+qGrs0uSulGL99jwiAn1Yt+CcNf7UOKXJXakJLq+qmU3Hy7l52WTdKMONaHJXaoJ7+oNcvDyEm5cnuzoU5USa3JWawE5VNfP3PYXcsGQyMSG6ros70eSu1AT22OZsfDw9uPfSVFeHopxMk7tSE9ih4jpWpkURo6sxuh1N7kpNYBWNFmJDfF0dhhoFmtyVmqAs1k7qWjp01O6mNLkrNUFVNbUD9k2qlfvR5K7UBFXR0AZAjJZl3JImd6UmqIpG+6bU0UFalnFHmtyVmqAqHcldR+7uSZO7UhNURaMFEYgM9HF1KGoUaHJXaoKqbGwjMtAXL09NA+5I31WlJqjKRovOlHFjmtyVmqAqGi1Ea3J3W5rclZqgKhp05O7ONLkrNQF1dNqobLIQqytBuq0Bk7uIrBeRChE53KNtgYjsFJH9IpIpIksd7SIij4pItogcFJFFoxm8Ump4TlU102kzpMYEuToUNUoGM3J/FrjirLZfAj82xiwAHnT8DHAlkOb4ugt40jlhKqWcKau8EYC0WE3u7mrA5G6M2QbUnN0MhDgehwIljsfrgOeN3U4gTETinRWsUso5ssqb8BCYFq3J3V15DfN59wHviMivsP+BWOFoTwAKe5xX5GgrPfsFROQu7KN7Jk+ePMwwlFLDcbK8keTIQN0z1Y0N94Lql4FvGGOSgG8Azwz1BYwxTxtjMowxGdHR0cMMQyk1HCfKG0nTertbG25yvxV43fH4FWCp43ExkNTjvERHm1JqjLBYO8mvbiE9LtjVoahRNNzkXgJc7Hi8BjjpeLwBuMUxa2Y5UG+MOacko5RynfdPVNJpM0yP1eTuzgasuYvIi8BqIEpEioCHgC8BvxMRL6ANR+0ceAtYC2QDLcDtoxCzUmqYSupa+c5rB5kZH8InZ8W6Ohw1igZM7saYG/s4tLiXcw1wz0iDUkqNjrcOlVLX0sFrX16hF1Pd3HBnyyilxomKxjb++lE+C5PDyatuJtTfW6dATgCa3JVyYy3tVtb+7gOqmtpZmhKBr7cHyZEBrg5LnQe6toxSbmxffh1VTe0kRfhzoryRgpoWJkdocp8INLkr5cZ2n6rGQ+CGJZOpb+0gv7pFR+4ThCZ3pdzYrlM1zEkIZdHk8O625IhAF0akzhdN7kq5KYu1k48L61iaEnHGDUuTdeQ+IWhyV8pN7cuvo91qY8mUCCICfbp3XdKyzMSgyV0pN/Kfw6UcKakH4O3Dpfh6ebAyNQqA9NhgfLw8iA3WDTomAp0KqZSbMMbwrVcPMmdSKH/94jLeOlTGmhkxBPra/ze/blECqTFBeHiIiyNV54Mmd6XcRG1LB41tVnbn1fDOkTKqmixcNW9S9/HrFiVy3aJEF0aozictyyjlJvKrmwHotBm+/epBwgK8WTMjxsVRKVfRkbtSbqKgpgUAHy8PmixWfnfDAvx9dP2YiUqTu1JuIr/antwfuHIGpfVtXDN/0gDPUO5Mk7tSbiK/uoW4ED9uv3CKq0NRY4DW3JVyEwU1zXqDkuqmyV0pN5FfrYuCqdM0uSvlBlrbO6lotJCsyV05aHJXyg0cLKoD0E2vVTdN7kq5gQ+zq/AQWD4t0tWhqDFCk7tSbmB7dhXzk8II8fN2dShqjNDkrtQ419DWwYGi+u4FwpQCTe5KjXt782rptBlWTNPkrk7T5K7UOJdT2QTADL2YqnrQ5K7UOJdf3UKwnxdhAVpvV6dpcldqnMuvsW96LaLrtKvTBkzuIrJeRCpE5PBZ7feKyHEROSIiv+zR/oCIZIvICRG5fDSCVkqdVlDdrJteq3MMZuT+LHBFzwYRuQRYB8w3xswGfuVonwXcAMx2POcJEdE1R5Vysi0nKiiua6XTZiiqbdU1ZdQ5BkzuxphtQM1ZzV8GfmGMsTjOqXC0rwNeMsZYjDGngGxgqRPjVWpCstkMxhgA9hXUcvuf9/DIu1mU1LVitRlddkCdY7g19+nARSKyS0S2isgSR3sCUNjjvCJH2zlE5C4RyRSRzMrKymGGodTE8Ojmk6z4xWbeP1HB99+wV0g/yqnq3qBDR+7qbMNN7l5ABLAc+Bbwsgzxao4x5mljTIYxJiM6OnqYYSg1Mbx9qIzS+jZu+/MeTpQ1sGZGDCX1bWzLsg+MkiO15q7ONNzNOoqA1439c+JuEbEBUUAxkNTjvERHm1JqmKqbLJwob+TWC5JJigjg8tlxdHTa2Hy8gr/tKiDAx5O4ED9Xh6nGmOEm938AlwBbRGQ64ANUARuAv4nII8AkIA3Y7YxAlZqodp+yX/K6ZkECi5PDATDGEBfiR1lDGw9/ei6eHjoNUp1pwOQuIi8Cq4EoESkCHgLWA+sd0yPbgVsdo/gjIvIycBSwAvcYYzpHK3ilJoKdudX4e3syLzG0u01E+MYn02hss/K5JZNdGJ0aqwZM7saYG/s4dHMf5/8M+NlIglJKnbYnr5ZFyWF4e555iUyTuuqP3qGq1Bhm7bSRXdHEnEmhA5+sVA+a3JUaw/Kqm2nvtOkOS2rINLkrNYadKLOv+Dg9VpO7GhpN7mpc2JtfS351s6vDOO9OlDXgIZAaE+TqUNQ4o8ldjXkNbR3c8swu/vvlA64O5bw7Ud5ISlQgft66RJMaGk3uakz57FM7+Mm/jnavowLw2t4imts72Ztfy8nyRhdGNzLGGHZkV9FssQ76OVnlTboJhxoWTe5qzKhv6WBPXi3rPzzFz98+Tn1rB80WK89/lE96bDDensLf9xQO/EJj1Gv7irnpT7v47FMfUVbfNuD59a0d5FU3kx4bch6iU+5Gk7saM044RuWz4kN4elsuS372Hqt/9T751c186/J0LpsVx8uZhdS3drg40qGrbLTwP28eZXpsEPnVzVz7+IccLWno9znbT1ZhDKxMizxPUSp3osldjRknyuzJ7k+3ZvDmvSv5/LLJpMcG88IXl/OJWbF85ZJpNLRZeeaDXBdHOnS/25RFS7uVJz6/mFfuXgHALet3sSO7ip/86yhNvZRqNh+vICzAmwVJ4ec7XOUGhru2jFJOd6K8kWA/L+JD/ZgU5s+chDNv3Jk9KZRPzY3nme2n+MolqePiImN1k4VDxfW8tLuQG5dO7p718twdS7nmse3c9KddgH02zE3LTt9xarMZtmZVsCotWteNUcOiI3c1qtqtNjo6bWe0GWP4xdvHWfXLLXzvjUPd7SfKGkmPDe53L9DLZsfS3N5JoWMd87Hujucyue3Pe/DyFL66JrW7PT0umP/77HxWp0eTGO7PmwdLznjetpOVVDW1c8kMXQ5bDY8mdzVqmixWlv3ve6R9/20e/s/x7vbNxyt4amsOAH/bVcCJskaMMRwvaxzwTszEcH8AiupaRy9wJ6lqsnCgsI4bliTxxlcuJPasZXmvmT+JZ29fyn8tTGBnbjWVjRaefD+HG5/eyQOvH2JqdCBXzol3UfRqvNPkrkbNjuwqals6iAz0YePRcsBebvj1u1kkRwbw+ldWEOTrxe82ZXGstJHGNuuA0/4Swuw7DhXXjv3k/mF2FQA3LZvMzPi+Z7xcNW8SNgOPb8nm0U0n2Z1XQ0WjhV9/dv64KD2psUlr7mrUbM2qJNDHk5uWTeaxLdk0tnXw+83ZHC1t4Defm09UkC9fvGgKv33vJJl5tYQHeLN2bv8j1ZhgX7w9haJxkNy3ZVURHuDN7AEW/UqPC+ZTc+N5dkceAG/eu5LwQB8SwvzPQ5TKXWlyV6PCGMPWrEpWpEaxODkcY+B/3jzKy5lF3HJBMtcusG+te++aNI6UNLDxaDmPXD+fyCDffl/Xw0OYFOZP8Rgvyxhj+OBkJRemRg3qguiP181m16lqFieHn3MhWanh0OSunK6wpoUn3s+mqLaVuy+exvzEMABezixiRlwwP7p6dvdFU08P4fc3LuRwcX33LkMDSQjzp7h2bAjK3pwAABPgSURBVF9QzSpvoqLRwqq0wV0QjQryZdN/r8bPRyulyjn0X5Jyuj9+kMvLmUWsmBbJFXPiCA/0YXKEvVZ+64oUPM4ayfp5e5KREtHvLJmeEsbQyP1oSQNX/HYbr+0tOqP9g5P2jatXpkUN+rVCA7zx9dIau3IOHbmrITHG8MjGLIL9vLpH2vMSz9wlaPvJKi5Ki+LZ25d2t2Ukh9PY1tFdjhmJxPAAyhssWKydLk2GW45X8LWXPqaxzcr33jiEn7cn0cG+xAT7su1kFakxQUzSurlyEU3ualDqWzp452gZk0L9+f3m7DOOBfp4khYbzA+vmkVcqB+5Vc1n3JAD8ODVs7jvE9Px9xl5Mk5wTIcsrWsjJSpwxK83HP86UMK9L37MzPgQHv70XO58LpN7/rav+7inh3DLBckuiU0p0OSuevGvAyX871vH+PPtS5gRZ5/C94v/HOPF3YUE+ngSFeTLM7dmUNPcTltHJztzq3nvWAVffG4P1y1KBOCis2rNYQE+hAX4OCW+JEdyz8yvdUlyN8bw2OZsZsQF88ZXVuDn7cnGb6wiu6KJtg4bG4+W8Zed+VwxO+68x6ZUF03uE0xOZRPRwb6E+Hn3evydI2V8/aWPsRl4Y18xD6wNobiulVf3FhEf6kdpfRv3rEllflJY93OunBvPHSubue6JHTyz/RQxwb5Mjx29zSUWJ4czLzGUn/77KKvSoog56+ag0bbrVA0nyht5+NNzu+ehhwX4kJESAdjr7A+snalz1JVL6QXVCeRoSQNX/vYDrntiB1VNlnOOF9a08M1XDjA3IZRlUyJ450gZxhh+9c4JAF7+fxfwwheXcddFU895bnJkIJvuv5jf37iQJ29eNOiLo8Ph5enBbz63gBZLJ09tPf+LiL20u4BQf2+umd/39QNN7MrVNLm7uc3Hy/nft45hsXby9Zc+JtjPi+LaVu57af8Z57W0W/nyC3vBwGM3LeLq+ZPIq27hh/88zBsfF/OV1akkRQRwYWoUXp69/7MJC/Dh6vmTWJwcMer9mhYdxMXp0bx1qBSbzQz8BCcxxrAjp5rV6dFOuX6g1GjRsoybe3xLDnvza2myWDlZ0cSfbsngeFkDv3o3i8KaFsICvPnUo9tpslipa2nnT7dmkBQRwGWzYnlowxH+urOAS9Kj+dqlaa7uyjmumhfPxqPlPLsjjy0nKjhYVM/G/15FTPDolWkKa1qpaLR0l2CUGqs0ubuxykYL+wpqAfsCXbPiQ7h0ZgzpccH86t0sNhwoYVp0EAU1LaxMjeKzGYmsmRELQEyIH699eQW+Xh6kxwafMzd9LLh0Ziw+Xh785M2jhPp7U9/awbasKj6zOHHUfufuvBoAlmpyV2PcgGUZEVkvIhUicriXY/eLiBGRKMfPIiKPiki2iBwUkUWjEbQanE3HyjEGLphq38nnrlVTERGSIgJYmhLB6/uKutd/WX/bEtadNQd9QVIYM+NDxmRiBwjy9eJbl6Vz98XT2P6dS4gK8u2+eain8oY2Vj68mYv/bwtvfFzUyysNXmZeDaH+3qTFjN4FY6WcYTA192eBK85uFJEk4DKgoEfzlUCa4+su4MmRh6iG692j5SSE+fP7mxbyvbUzuGre6UW5blyWRE5lM6/uLeSCaVH4eI3Pyy9fWjWV7145g2A/b1amRvJhdtU5Nfifv3WMikYL/t6ePPiPI1Q2WqhvOXerPou1k8c2n+TW9bvJ6mUj7narjQ9zqshIDh+zf/CU6jLg/9HGmG1ATS+HfgN8G+j5f9I64HljtxMIExFdkNoFCmtaeP9EBesWTCIqyJe7Vk0740LouvkJzEkIoaPTsGr64G+RH8suSoumqqmdI469SQ8X13PL+t38Y38Jd6+aymM3LaS53cqqX25hxS82UdPcfsbz12/P41fvZvFRbjX3v3yAB/95uHvdeYDfbz5JYU0rNyw98wYtpcaiYQ3XRGQdUGyMOXDWoQSg5/b0RY623l7jLhHJFJHMyspzP0qrkfnzh3l4iHDLBSm9HvfwEH58zRymRgfyyVmx5ze4UbI6PZpgXy++9eoB6ls7+OYrBzhcXM8XV07hK5ekkhoTzJdXT2NKVCDN7Z3853DZGc/fcryC2ZNC+M31CzhUXM/zH+XzyMYsqpss5FQ28fiWbD69KNFt/nsp9zbk5C4iAcD3gAdH8ouNMU8bYzKMMRnR0bqVmDMV1rTw9z0FXDUvnrjQvmeOLE4OZ/P9q4kPdY/1TyKDfHni5kWcrGji0l+/z/GyRn58zWx+cNWs7nnn37p8Bv/+2kqmRgXy9z0FfOn5THafqqG+tYO9BbVckh7D2rlx/PTaOfzy0/Not9p4aU8h67efwsvTg+9eOcPFvVRqcIYzW2YaMAU44LhRJRHYJyJLgWIgqce5iY42dZ5YO23c9/f9eIhw/2Xprg7nvLsoLZpnb1/Ct145yIKkMD7Vy+YfIsJV8+J5dHM2UI+Plwdr58TTaTOsTo9GRLh5uX1dmA0HSvjD1hwsVhvXLUwgOrj/9eaVGiuGnNyNMYeAmK6fRSQPyDDGVInIBuCrIvISsAyoN8aUOitYNbCNR8vZm1/LI9fPJ8mxzO5Ec1FaNB985xI6babPC5+fzUhiZ24Nlk4b20/aL8KG+nuzoMeyCmDfRONHG46QmVfLF3u5M1epsWrA5C4iLwKrgSgRKQIeMsY808fpbwFrgWygBbjdSXGqQXptXzExwb7nTGucaLw9PehvBYCkiABevvuC7tUd3z5cxl2rpp5z9+206CD+cucybP38oVBqLBowuRtjbhzgeEqPxwa4Z+RhqeGobrLw/okK7lw5ZVBbuylYmRqFh4CHCLetSOnzPE3sarzRO1TdyIYDJVhtpnvZXTWw8EAfrpgTR2yIn26sodyKJnc38vq+YuYkhJAeF+zqUMaVJz6/2NUhKOV04/O2RHWOrPJGDhXXc91CHbUrpTS5uwVjDH/YmouXh3DNgkmuDkcpNQZoch/nbDbDd147yGv7irhz5RSignQetlLKzWruVU0W2q22My6MPfyf4xwpaeCi1CjuXDnF7WY9/OTNo7ycWcTX1qTyjU9Od3U4SqkxYlyP3BvaOnhkYxYdnTY6bYab/7SLG57eic1mMMZQ1WThD1tzOFpSz8/eOsZXX9yHxdrp6rCdZk9eDc/uyOP2C1P4xienj+rWdkqp8WVcj9w3HSvn0U0nOVJcz+KUcI6X2Zdp/fXGE7ySWcSFqVHYDPzlzmV8mF3FT/99jLaOfTx18+Jxt8Rtu9WGl4ec8cnjsc3ZRAb68O3LZ2hiV0qdYVwn9/9amEizpZMf/vMwm45XMC8xlLyqZh7fYl+m9Y2Pi5kWHciMuGBmxofg6+XBD/95hP8cKeOa+ePnwmNxXSuf+PVWOjptfP3SNO69NI0DhXVszark21ek616eSqlzjK/hay9uXp7M+99cze9uWMATn1/Ufdv9/Y7689XzJ3WPam9alkywrxcf5VS7LN7heDWziDZrJxdMi+SR97L4MLuKX7x9nIhAH77gWOBKKaV6Gtcj9y7JkYEkRwYC8K0r0lm3YBIZKRFcOjOWqdGB3ed5eghLpkSw69T4Se42m+GVvYWsmBbJH76wmKt+v50vPLMLm4GHrp5FsJ+3q0NUSo1B437kfrYQP+/unelnTQrpXse7y/KpEeRWNlPR0OaK8IZs56lqimpbuT4jiQAfL166azm3rkjhk7NiuWmZ7giklOqdW4zch2K5Y7PoDQdKaG3vpLalgwevnuXiqPr2SmYRwX5eXD47DoCYYD8eunq2i6NSSo11Ey65z4oPYVp0ID/997HutnvXpBIe6DPk16pusuDl6UGov/NLIx2dNhpaO3jrUCmfWZx4zicQpZTqz4RL7l6eHvz7axfxzpEyCqpb+PXGLPYX1nHJjJiBn9yDMYYb/7iTxPAA1t+2xOlx3v7nPXyUW02nzXB9RtLAT1BKqR7cruY+GH7enqxbkMCdF03BQ+Djgtohv8aRkgayypv44GQljW0d2Jeyd45TVc1sz65iTkIoNy5NYl5iqNNeWyk1MUy4kXtPAT5ezIgL4ePCOgA2Hy9nUpg/M+JCzjn3t+9lsa+gjl9cN5dJYf7862AJAB2dhm+/epA9ebX8+bYlzB1mIs6pbOLJ93O4fHYcmfk1eAj84ebF/W5wrZRSfZmQI/eeFk4OY39BHSV1rXzxuUyuffxDthyvwBjDwaI6bDbD4eJ6Ht10km1ZlVzz2IfUt3Tw5oFSLkqLItTfm7cPl1HVZOHuv+7llcxCmizWIcfx1535vLq3iC89n8kftuayMi1aE7tSatgmfHJfkhJBo8XKfS/tx2ZgUqg/P/jHYf59qJRrHvuQu/+6l6+9+DERgb48e/sSqpos3PO3fRTX2acnfmJmLP7enjx200KaLFa+9epBvvzXvUMu02zLquTC1EieuTWDOy6cwjcv00XAlFLDN+GT+6fmxTMrPoTdeTVclBbFFy+aSnFdK0++n4OPlwfvHi2nraOT392wgNXpMSyaHMb27ComRwRw5Zw4Hrx6Fu/ct4qr5k1i7w8+wffXzuSDk1VsOFAy6BiKalvIqWxmzYxYLp0Zy4NXz2JeYtgo9lop5e4mdM0dwNvTg19fP58bnt7JHSunkB5r36LuSEkDn1mcyN0XTyUxPKB7KuKtK1LYV7CfL62a6pgGeXoqpJenB3esnMKbh0p58J9HWJwcTmJ4QPfvenpbDluzKlmcHEFpXSsRQT7cckEK27KqALh4etR57r1Syl1N+OQOMDM+hP0PfrJ7DZr02GBOlDfyiZkxpMacuR/p1fMmEeLvzaq06F5fy9ND+N3nFnDV77dzz98+5snPL+K372XxuSVJ/H5TNu2dNj7MriY62Jfa5nbeO1pOW4eNlMgApkUHjXpflVITgyZ3h55L5l4+O5ai2hZW9pLAPTyES9L7nxOfEhXIr6+fz91/3cslv3ofi9XGhgMltHXYeOXuC5gzKRR/H0925FTxhWd24+flwd//3wW6bK9SymnEmfOzhysjI8NkZma6Ooxu7VYbNc3tI56t8ted+Tz89nGuX5LEM9tPkRYTxLvfWHVGEt+RXUWIvzdzEnQuu1JqaERkrzEmo7djA47cRWQ9cBVQYYyZ42j7P+BqoB3IAW43xtQ5jj0A3Al0Al8zxrzjlF6cRz5eHk6Zhnjz8mRuXDoZTw8hNsSXWfGh54zOV6RqnV0p5XyDmS3zLHDFWW0bgTnGmHlAFvAAgIjMAm4AZjue84SITOhFUTwdOyfdtWoaK9M0kSulzo8Bk7sxZhtQc1bbu8aYrjt1dgKJjsfrgJeMMRZjzCkgG1jqxHiVUkoNgjPmud8BvO14nAAU9jhW5GhTSil1Ho0ouYvI9wEr8MIwnnuXiGSKSGZlZeVIwlBKKXWWYSd3EbkN+4XWz5vTU26KgZ7r0yY62s5hjHnaGJNhjMmIju59zrhSSqnhGVZyF5ErgG8D1xhjWnoc2gDcICK+IjIFSAN2jzxMpZRSQzGYqZAvAquBKBEpAh7CPjvGF9jomNq30xhztzHmiIi8DBzFXq65xxjTOVrBK6WU6p3exKSUUuNUfzcxTfhVIZVSyh2NiZG7iFQC+cN8ehRQ5cRwxgPts/ubaP0F7fNwJBtjep2RMiaS+0iISGZfH0vclfbZ/U20/oL22dm0LKOUUm5Ik7tSSrkhd0juT7s6ABfQPru/idZf0D471bivuSullDqXO4zclVJKnUWTu1JKuaFxndxF5AoROSEi2SLyXVfHM1pEJE9EDonIfhHJdLRFiMhGETnp+B7u6jiHS0TWi0iFiBzu0dZr/8TuUcd7flBEFrku8uHro88/EpFix/u8X0TW9jj2gKPPJ0TkctdEPXwikiQiW0TkqIgcEZGvO9rd9n3up8/n5302xozLL8AT+xZ/UwEf4AAwy9VxjVJf84Cos9p+CXzX8fi7wMOujnME/VsFLAIOD9Q/YC32/QMEWA7scnX8Tuzzj4Bv9nLuLMe/b19giuPfvaer+zDE/sYDixyPg7Hv4DbLnd/nfvp8Xt7n8TxyXwpkG2NyjTHtwEvYd4KaKNYBzzkePwdc68JYRsT0stsXffdvHfC8sdsJhIlI/PmJ1Hn66HNfxv0OZ8aYUmPMPsfjRuAY9o183PZ97qfPfXHq+zyek/tE2vXJAO+KyF4RucvRFmuMKXU8LgNiXRPaqOmrf+7+vn/VUYZY36PU5lZ9FpEUYCGwiwnyPp/VZzgP7/N4Tu4TyUpjzCLgSuAeEVnV86Cxf6Zz2zmt7t6/Hp4EpgELgFLg164Nx/lEJAh4DbjPGNPQ85i7vs+99Pm8vM/jObkPeten8c4YU+z4XgG8gf2jWnnXx1TH9wrXRTgq+uqf277vxphyY0ynMcYG/JHTH8ndos8i4o09yb1gjHnd0ezW73NvfT5f7/N4Tu57gDQRmSIiPsAN2HeCcisiEigiwV2PgcuAw9j7eqvjtFuBf7omwlHTV/82ALc4ZlMsB+p7fKwf186qKf8X9vcZ3GCHM7Hv6vMMcMwY80iPQ277PvfV5/P2Prv6ivIIr0avxX4FOgf4vqvjGaU+TsV+Bf0AcKSrn0AksAk4CbwHRLg61hH08UXsH087sNcZ7+yrf9hnTzzueM8PARmujt+Jff6Lo08HHf+jx/c4//uOPp8ArnR1/MPo70rsJZeDwH7H11p3fp/76fN5eZ91+QGllHJD47kso5RSqg+a3JVSyg1pcldKKTekyV0ppdyQJnellHJDmtyVUsoNaXJXSik39P8B9PcDrDTtXPIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}